{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities for Thesis\n",
    "### Figure generators and such"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import madmom\n",
    "from madmom.audio.filters import LogarithmicFilterbank, MelFilterbank\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, get_window\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "\n",
    "class Debugger:\n",
    "    def __init__(self, debug):\n",
    "        self.debug = debug\n",
    "        \n",
    "    def log(self, *msg):\n",
    "        if(self.debug):\n",
    "            print(*msg)\n",
    "            \n",
    "dbg = Debugger(debug)\n",
    "dbg.log('debugger', 'initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals Variables and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio file\n",
    "AUDIO_FILE_NAME = 'zztop_badtothebone_mono_5sec.wav'\n",
    "AUDIO_PATH_RELATIVE = '../../audio_for_thesis'\n",
    "AUDIO_LEN = 5\n",
    "FS = None\n",
    "AUDIO_BUFFER = None\n",
    "\n",
    "assert os.path.exists(AUDIO_PATH_RELATIVE), 'Folder doesnt exist: {}'.format(AUDIO_PATH_RELATIVE)\n",
    "\n",
    "# figures\n",
    "FIG_FOLDER = 'utilities_for_thesis_figures'\n",
    "FIG_SIZE = (9,6)\n",
    "DPI = 80\n",
    "\n",
    "assert os.path.exists(FIG_FOLDER), 'Folder doesnt exist: {}'.format(FIG_FOLDER)\n",
    "\n",
    "# framing\n",
    "FRAMING_FRAME_SIZE = 256 #128\n",
    "FRAMING_HOP_SIZE = 152 #76 #96\n",
    "FRAMING_FRAME_N = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Functions and Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fig_save_path(fig_name):\n",
    "    return os.path.join(FIG_FOLDER, fig_name)\n",
    "\n",
    "# 0 <= n <= N-1\n",
    "def hann(n, N):\n",
    "    return 0.5 * (1 - math.cos((2 * math.pi * n) / (N - 1)))\n",
    "\n",
    "v_hann = np.vectorize(hann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio():\n",
    "    audio_path = os.path.join(os.getcwd(), AUDIO_PATH_RELATIVE)\n",
    "    audio_path_absolute = os.path.abspath(audio_path)\n",
    "    assert os.path.exists(audio_path_absolute), 'Audio file path doesnt exist: {}'.format(audio_path_absolute)\n",
    "\n",
    "    audio_path_full = os.path.join(audio_path_absolute, AUDIO_FILE_NAME)\n",
    "    assert os.path.exists(audio_path_full), 'Audio file doesnt exist: {}'.format(audio_path_full)\n",
    "\n",
    "    fs, audio_buffer = wavfile.read(audio_path_full)\n",
    "\n",
    "    assert fs == 44100, 'Sampling rate should be 44100 Hz'\n",
    "    assert len(audio_buffer.shape) == 1, 'Audio should be mono'\n",
    "    assert len(audio_buffer) == AUDIO_LEN * fs, 'Audio should be exactly %d seconds long' %(AUDIO_LEN)\n",
    "\n",
    "    dbg.log(audio_path_full)\n",
    "    dbg.log('audio buffer shape:', audio_buffer.shape, 'sampling rate:', fs)\n",
    "    \n",
    "    return fs, audio_buffer\n",
    "\n",
    "FS, AUDIO_BUFFER = load_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Domain Audio Signal Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_domain(figsize, dpi, save_path):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(AUDIO_BUFFER/AUDIO_BUFFER.max())\n",
    "    audio_ticks = np.arange(0, len(AUDIO_BUFFER), FS/2)\n",
    "    plt.xticks(audio_ticks, [\"{:.1f}\".format(tick/FS) for tick in audio_ticks], rotation='45')\n",
    "    plt.xlim([0, len(AUDIO_BUFFER)])\n",
    "    plt.xlabel('Time (Seconds)')\n",
    "    plt.ylabel('Amplitude (Normalized)');\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi)\n",
    "    \n",
    "plot_time_domain(FIG_SIZE, DPI, get_fig_save_path('time_domain.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Domain Audio Signal Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frequency_domain(figsize, dpi, save_path):\n",
    "    '''\n",
    "    # Original:\n",
    "\n",
    "    frame_size = 2048\n",
    "    start_frame = 2*FS\n",
    "\n",
    "    frame = AUDIO_BUFFER[start_frame:start_frame+frame_size]\n",
    "    spectrum = np.fft.fft(frame)\n",
    "\n",
    "    abs_spec_size = int(frame_size/2+1)\n",
    "    abs_spec = np.abs(spectrum)[:abs_spec_size]\n",
    "\n",
    "    fft_freqs = np.fft.fftfreq(frame_size)*FS\n",
    "    freq_ticks = np.arange(0, abs_spec_size, 128, dtype=int)\n",
    "    freq_tick_labels = [\"{:.1f}Hz\".format(np.abs(fft_freqs[idx])) for idx in freq_ticks]\n",
    "    print(fft_freqs[1024])\n",
    "\n",
    "\n",
    "    plt.plot(abs_spec/abs_spec.max())\n",
    "    plt.xticks(freq_ticks, freq_tick_labels, rotation=\"45\");\n",
    "    '''\n",
    "\n",
    "    frame_size = AUDIO_LEN * FS # 220500\n",
    "\n",
    "    frame = AUDIO_BUFFER[0:frame_size] # take whole 5sec clip as frame\n",
    "    spectrum = np.fft.fft(frame) # fft resolution is same as size of AUDIO_BUFFER (220500)\n",
    "\n",
    "    abs_spec_size = int(frame_size/2+1) # half cause mirrored (110251)\n",
    "    abs_spec = np.abs(spectrum)[:abs_spec_size] # absolute values of half\n",
    "\n",
    "    # frequency bin centers [0...0.5,-0.5...-0]\n",
    "    # result in requency values when multiplied by sampling rate (cause same as resolution) (same as specifying d=1/sampling_rate)\n",
    "    # with 220500 values\n",
    "    # will only be used until index half, cause they are then mirrored in the negative\n",
    "    fft_freqs = np.fft.fftfreq(frame_size)*FS\n",
    "    dbg.log(fft_freqs[110250])\n",
    "\n",
    "    # indices to be used, only go until 110251, cause of mirroring\n",
    "    # 110251 / 7 = 15750.14, round down to get 8 indices instead of 7\n",
    "    freq_ticks = np.arange(0, abs_spec_size, 15750, dtype=int)\n",
    "    # labels (with Hz as value) for the corresponding indices\n",
    "    freq_tick_labels = [\"{:.1f}\".format(np.abs(fft_freqs[idx])) for idx in freq_ticks]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(abs_spec/abs_spec.max())\n",
    "    plt.xticks(freq_ticks, freq_tick_labels, rotation=\"45\")\n",
    "\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude / Power (Normalized)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi)\n",
    "\n",
    "    dbg.log('spectrum resolution:', abs_spec.shape)\n",
    "    dbg.log('fft frequencies:', fft_freqs.shape)\n",
    "    dbg.log('indices to be used for freq. values:', freq_ticks)\n",
    "    dbg.log('frequencies at above indices taken from fft frequencies:', freq_tick_labels)\n",
    "    \n",
    "plot_frequency_domain(FIG_SIZE, DPI, get_fig_save_path('frequency_domain.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framing (frame size, hop size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_before_framing(figsize, dpi, save_path):\n",
    "    frame_size = FRAMING_FRAME_SIZE\n",
    "    hop_size = FRAMING_HOP_SIZE\n",
    "    frame_n = FRAMING_FRAME_N\n",
    "\n",
    "    start_sample = int(0.5*FS)\n",
    "\n",
    "    audio_segment = AUDIO_BUFFER[start_sample: start_sample + ((frame_n-1)*(hop_size)) + frame_size]\n",
    "    dbg.log('segment length: {} samples'.format(audio_segment.size))\n",
    "    \n",
    "    # calculate signal frames\n",
    "    frames = []\n",
    "    frames_start = []\n",
    "    frames_end = []\n",
    "    for i in range(0, frame_n):\n",
    "        start_curr = start_sample + i * hop_size\n",
    "        f = AUDIO_BUFFER[start_curr: start_curr +  frame_size]\n",
    "        dbg.log('{} frame size: {} samples'.format(i+1, f.size))\n",
    "        frames.append(f)\n",
    "        frames_start.append(i*hop_size)\n",
    "        frames_end.append((i*hop_size + frame_size)-1)\n",
    "    \n",
    "    # plot signal and highlight overlap\n",
    "    plt.figure(figsize=(figsize[0], 0.5*figsize[1]))\n",
    "    plt.plot(audio_segment/audio_segment.max())\n",
    "\n",
    "    plt.axvspan(hop_size, frame_size-1, color='red', alpha=0.15)\n",
    "    plt.axvspan(2*hop_size, (frame_size + hop_size)-1, color='red', alpha=0.15)\n",
    "\n",
    "    # X-Axis and Y-Axis\n",
    "    audio_ticks = np.arange(0, audio_segment.size, int(audio_segment.size/9))\n",
    "    plt.xticks(audio_ticks, [\"{:.0f}\".format(tick+1) for tick in audio_ticks], rotation='45')\n",
    "    plt.xlim([0, audio_segment.size])\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude');\n",
    "\n",
    "    # top X-Axis\n",
    "    ax_overlap = plt.twiny()\n",
    "    overlap_ticks = np.concatenate((frames_start, frames_end))\n",
    "    ax_overlap.set_xticks(overlap_ticks)\n",
    "    overlap_labels = np.array([((i%3)+1, tick+1) for i, tick in enumerate(overlap_ticks)])\n",
    "    ax_overlap.set_xticklabels([\"F{}: {:.0f}\".format(frame_n, sample) for frame_n, sample in (overlap_labels)])\n",
    "    ax_overlap.set_xlim([0, audio_segment.size])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi)\n",
    "    \n",
    "    x_start, x_end, y_start, y_end = plt.axis()\n",
    "    \n",
    "    return audio_segment, frames, x_start, x_end, y_start, y_end, overlap_ticks, overlap_labels\n",
    "    \n",
    "FRAMING_AUDIO_SEGMENT, FRAMING_FRAMES, FRAME_X_AX_START, FRAME_X_AX_END, FRAME_Y_AX_START, FRAME_Y_AX_END, \\\n",
    "    FRAMING_OVERLAP_TICKS, FRAMING_OVERLAP_LABELS \\\n",
    "    = plot_signal_before_framing(FIG_SIZE, DPI, get_fig_save_path('signal_before_framing.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_after_framing(figsize, dpi, save_path, audio_segment, frames, \\\n",
    "                              x_start, x_end, y_start, y_end, overlap_ticks, overlap_labels, smoothing = False):\n",
    "    frame_size = FRAMING_FRAME_SIZE\n",
    "    hop_size = FRAMING_HOP_SIZE\n",
    "    frame_n = FRAMING_FRAME_N\n",
    "\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(figsize[0], 1.5*figsize[1]))\n",
    "\n",
    "    # 1 frame\n",
    "    for i in range(0, frame_n):\n",
    "\n",
    "        # plot 1 frame and highlight overlap\n",
    "        f = frames[i]\n",
    "\n",
    "        if(smoothing):\n",
    "            sample_idxs = np.arange(0, frame_size)\n",
    "            smoothing_coefficients = v_hann(sample_idxs, frame_size)\n",
    "            f = smoothing_coefficients * f\n",
    "\n",
    "        f_norm = f/audio_segment.max()\n",
    "        frame_in_segment = np.full(audio_segment.size, None)\n",
    "        frame_in_segment[i*hop_size :i*hop_size + f_norm.size] = f_norm\n",
    "\n",
    "        ax[i].plot(frame_in_segment)\n",
    "        if i != 2:\n",
    "            ax[i].axvspan(hop_size, f.size-1, color='red', alpha=0.15)\n",
    "        if i != 0:\n",
    "            ax[i].axvspan(2*hop_size, (f.size + hop_size)-1, color='red', alpha=0.15)\n",
    "\n",
    "        #ax[i].set_title('Frame {}'.format(i+1))\n",
    "\n",
    "        # labels, limits and ticks\n",
    "        if i == 2:\n",
    "            ax[i].set_xlabel('Sample')\n",
    "        ax[i].set_ylabel('Amplitude');\n",
    "\n",
    "        ax[i].set_xlim([x_start, x_end])\n",
    "        ax[i].set_ylim([y_start, y_end])\n",
    "\n",
    "        if i == 2:\n",
    "            audio_ticks = np.arange(0, audio_segment.size, int(audio_segment.size/9))\n",
    "            ax[i].set_xticks(audio_ticks)\n",
    "            ax[i].set_xticklabels([\"{:.0f}\".format(tick+1) for tick in audio_ticks], rotation=45)\n",
    "        else:\n",
    "            ax[i].set_xticks([])\n",
    "\n",
    "        # top X-Axes\n",
    "        ax_x2 = ax[i].twiny()\n",
    "\n",
    "        lower_bound = i*hop_size <= overlap_ticks\n",
    "        upper_bound = overlap_ticks <= (i*hop_size) + frame_size\n",
    "        bound = lower_bound * upper_bound\n",
    "        ax_x2.set_xticks(overlap_ticks[bound])\n",
    "\n",
    "        lower_bound = i*hop_size <= overlap_labels[:,1]\n",
    "        upper_bound = overlap_labels[:,1] <= (i*hop_size) + frame_size\n",
    "        bound = lower_bound * upper_bound\n",
    "        ax_x2.set_xticklabels([\"F{}: {:.0f}\".format(frame_n, sample) for frame_n, sample in overlap_labels[bound]])\n",
    "\n",
    "        ax_x2.set_xlim([x_start, x_end])\n",
    "\n",
    "        # right Y-Axes\n",
    "        ax_y2 = ax[i].twinx()\n",
    "        ax_y2.set_yticks([])\n",
    "        ax_y2.set_ylabel('Frame {}'.format(i+1), labelpad=10);\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.25)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(save_path, dpi=dpi)\n",
    "\n",
    "plot_signal_after_framing(FIG_SIZE, DPI, get_fig_save_path('signal_after_framing.png'), \\\n",
    "    FRAMING_AUDIO_SEGMENT, FRAMING_FRAMES, FRAME_X_AX_START, FRAME_X_AX_END, FRAME_Y_AX_START, FRAME_Y_AX_END, \\\n",
    "    FRAMING_OVERLAP_TICKS, FRAMING_OVERLAP_LABELS)\n",
    "\n",
    "plot_signal_after_framing(FIG_SIZE, DPI, get_fig_save_path('signal_after_framing_with_smoothing.png'), \\\n",
    "    FRAMING_AUDIO_SEGMENT, FRAMING_FRAMES, FRAME_X_AX_START, FRAME_X_AX_END, FRAME_Y_AX_START, FRAME_Y_AX_END, \\\n",
    "    FRAMING_OVERLAP_TICKS, FRAMING_OVERLAP_LABELS, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame_1(audio_segment, frames, y_start, y_end):\n",
    "    hop_size = FRAMING_HOP_SIZE\n",
    "    \n",
    "    f = frames[0]\n",
    "    plt.plot(f/audio_segment.max())\n",
    "    audio_ticks = np.arange(0, f.size, int(f.size/8))\n",
    "    plt.xticks(audio_ticks, [\"{:.0f}\".format(tick + (0*hop_size)) for tick in audio_ticks], rotation='45')\n",
    "    plt.xlim([0, f.size])\n",
    "\n",
    "    plt.ylim([y_start, y_end])\n",
    "\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude');\n",
    "    \n",
    "plot_frame_1(FRAMING_AUDIO_SEGMENT, FRAMING_FRAMES, FRAME_Y_AX_START, FRAME_Y_AX_END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame_2(audio_segment, frames, y_start, y_end):\n",
    "    hop_size = FRAMING_HOP_SIZE\n",
    "    \n",
    "    f = frames[1]\n",
    "    plt.plot(f/audio_segment.max())\n",
    "\n",
    "    plt.axvspan(0, f.size, color='red', alpha=0.15)\n",
    "\n",
    "    audio_ticks = np.arange(0, f.size, int(f.size/8))\n",
    "    plt.xticks(audio_ticks, [\"{:.0f}\".format(tick + (1*hop_size)) for tick in audio_ticks], rotation='45')\n",
    "    plt.xlim([0, f.size])\n",
    "\n",
    "    plt.ylim([y_start, y_end])\n",
    "\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude');\n",
    "    \n",
    "plot_frame_2(FRAMING_AUDIO_SEGMENT, FRAMING_FRAMES, FRAME_Y_AX_START, FRAME_Y_AX_END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame_3(audio_segment, frames, y_start, y_end):\n",
    "    hop_size = FRAMING_HOP_SIZE\n",
    "    \n",
    "    f = frames[2]\n",
    "    plt.plot(f/audio_segment.max())\n",
    "    audio_ticks = np.arange(0, f.size, int(f.size/8))\n",
    "    plt.xticks(audio_ticks, [\"{:.0f}\".format(tick + (2*hop_size)) for tick in audio_ticks], rotation='45')\n",
    "    plt.xlim([0, f.size])\n",
    "\n",
    "    plt.ylim([y_start, y_end])\n",
    "\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude');\n",
    "    \n",
    "plot_frame_3(FRAMING_AUDIO_SEGMENT, FRAMING_FRAMES, FRAME_Y_AX_START, FRAME_Y_AX_END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hann Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widnow function\n",
    "def plot_hann_window(figsize, dpi, save_path):\n",
    "    frame_size = 441\n",
    "    sample_idxs = np.arange(0, frame_size)\n",
    "    smoothing_coefficients = v_hann(sample_idxs, frame_size)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(smoothing_coefficients)\n",
    "\n",
    "    x_ticks = np.arange(0, frame_size, 44, dtype=int)\n",
    "    plt.xticks(x_ticks, [\"{:.0f}\".format(tick+1) for tick in x_ticks], rotation='45')\n",
    "    plt.xlim([0, frame_size])\n",
    "\n",
    "    plt.xlabel('Sample');\n",
    "    plt.ylabel('Smoothing Coefficient');\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi)\n",
    "\n",
    "    dbg.log('sample values:', v_hann([0, 110 ,220 ,330 ,440], frame_size))\n",
    "    \n",
    "plot_hann_window(FIG_SIZE, DPI, get_fig_save_path('hann_window.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio frame (not smoothed)\n",
    "def plot_frame_before_smoothing(figsize, dpi, save_path):\n",
    "    frame_size = 441\n",
    "    frame_start = int(0.5 * FS) # start at 0.5sec\n",
    "    frame_end = frame_start + frame_size\n",
    "    frame = AUDIO_BUFFER[frame_start: frame_end]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(frame / frame.max())\n",
    "\n",
    "    x_ticks = np.arange(0, frame_size, 44, dtype=int)\n",
    "    plt.xticks(x_ticks, [\"{:.0f}\".format(tick+1) for tick in x_ticks], rotation='45')\n",
    "    plt.xlim([0, frame_size])\n",
    "\n",
    "    plt.xlabel('Sample');\n",
    "    plt.ylabel('Amplitude');\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi)\n",
    "\n",
    "    x_ax_start, x_ax_end, y_ax_start, y_ax_end = plt.axis()\n",
    "    return x_ax_start, x_ax_end, y_ax_start, y_ax_end\n",
    "    \n",
    "HANN_X_AX_START, HANN_X_AX_END, HANN_Y_AX_START, HANN_Y_AX_END = plot_frame_before_smoothing(FIG_SIZE, DPI, get_fig_save_path('frame_without_smoothing.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio frame (smoothed)\n",
    "def plot_frame_after_smoothing(figsize, dpi, save_path, x_start, x_end, y_start, y_end):\n",
    "    frame_size = 441\n",
    "    frame_start = int(0.5 * FS) # start at 0.5sec\n",
    "    frame_end = frame_start + frame_size\n",
    "    frame = AUDIO_BUFFER[frame_start: frame_end]\n",
    "    sample_idxs = np.arange(0, frame_size)\n",
    "    smoothing_coefficients = v_hann(sample_idxs, frame_size)\n",
    "    smoothed_frame = smoothing_coefficients * frame\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(smoothed_frame / frame.max())\n",
    "\n",
    "    x_ticks = np.arange(0, frame_size, 44, dtype=int)\n",
    "    plt.xticks(x_ticks, [\"{:.0f}\".format(tick+1) for tick in x_ticks], rotation='45')\n",
    "    plt.xlim([x_start, x_end])\n",
    "\n",
    "    y_ticks = np.arange(-1, 1.5, 0.5)\n",
    "    plt.yticks(y_ticks)\n",
    "    plt.ylim([y_start, y_end])\n",
    "\n",
    "    plt.xlabel('Sample');\n",
    "    plt.ylabel('Amplitude');\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi)\n",
    "    \n",
    "plot_frame_after_smoothing(FIG_SIZE, DPI, get_fig_save_path('frame_with_smoothing.png'), HANN_X_AX_START, HANN_X_AX_END, HANN_Y_AX_START, HANN_Y_AX_END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time/Frequency Domain Audio Signal Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrogram\n",
    "def plot_spectrogram(figsize, dpi, save_path, compute_log=False, compute_log_mel=False):\n",
    "    frame_size = 4096\n",
    "    hop_size = 441\n",
    "    sample_rate = FS\n",
    "    frame_rate = 100\n",
    "    \n",
    "    window = get_window('hann', frame_size)\n",
    "    overlap = frame_size - sample_rate / frame_rate # frame size - hop size\n",
    "    \n",
    "    # spectrogram\n",
    "    frequencies, times, spec = spectrogram(AUDIO_BUFFER, fs=FS, window=window, noverlap=overlap)\n",
    "    # base 10 log spectrogram\n",
    "    log_spec = np.log10(spec+1)\n",
    "    # mel scaled base 10 log spectrogram\n",
    "    filterbank = LogarithmicFilterbank(frequencies).T #MelFilterbank(frequencies).T\n",
    "    mel_freq_bins = LogarithmicFilterbank(frequencies).center_frequencies #MelFilterbank(frequencies).center_frequencies\n",
    "    log_mel_spec = np.log10(np.matmul(filterbank, spec) + 1)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    if(compute_log):\n",
    "        plt.imshow(log_spec, interpolation=None, origin='lower', aspect='auto')\n",
    "    elif(compute_log_mel):\n",
    "        plt.imshow(log_mel_spec, interpolation=None, origin='lower', aspect='auto')\n",
    "    else:\n",
    "        plt.imshow(spec, interpolation=None, origin='lower', aspect='auto')\n",
    "    \n",
    "    t_tick_idxs = np.arange(0, len(times), 100, dtype=int)\n",
    "    t_tick_lbls = [\"{:.1f}\".format(tick/100) for tick in t_tick_idxs]\n",
    "    f_tick_idxs = np.arange(0, len(frequencies), int(len(frequencies)/8))\n",
    "    f_tick_lbls = [\"{:.1f}\".format(tick) for tick in frequencies[f_tick_idxs]]\n",
    "    if(compute_log_mel):\n",
    "        f_tick_idxs = np.append(np.arange(0, len(mel_freq_bins), 10), len(mel_freq_bins)-1)\n",
    "        f_tick_lbls = [\"{:.1f}\".format(tick) for tick in mel_freq_bins[f_tick_idxs]]\n",
    "    plt.xticks(t_tick_idxs, t_tick_lbls, rotation='45')\n",
    "    plt.yticks(f_tick_idxs, f_tick_lbls)\n",
    "    \n",
    "    plt.xlabel('Time (seconds)');\n",
    "    plt.ylabel('Frequency (Hz)');\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi)\n",
    "    \n",
    "    dbg.log((AUDIO_BUFFER.size - frame_size) / 441)\n",
    "    dbg.log(times.shape)\n",
    "    dbg.log(frequencies.size)\n",
    "    dbg.log(spec.shape)\n",
    "    \n",
    "    dbg.log(filterbank.shape)\n",
    "    dbg.log(mel_freq_bins.shape)\n",
    "\n",
    "plot_spectrogram(FIG_SIZE, DPI, get_fig_save_path('spectrogram.png'))\n",
    "plot_spectrogram(FIG_SIZE, DPI, get_fig_save_path('log_spectrogram.png'), compute_log=True)\n",
    "plot_spectrogram(FIG_SIZE, DPI, get_fig_save_path('log_filtered_spectrogram.png'), compute_log_mel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mel_scale(figsize, dpi, save_path):\n",
    "    frame_size = 4096\n",
    "    hop_size = 441\n",
    "    sample_rate = FS\n",
    "    frame_rate = 100\n",
    "    \n",
    "    window = get_window('hann', frame_size)\n",
    "    overlap = frame_size - sample_rate / frame_rate # frame size - hop size\n",
    "    \n",
    "    # mel scale\n",
    "    frequencies, _, _= spectrogram(AUDIO_BUFFER, fs=FS, window=window, noverlap=overlap)\n",
    "    filterbank = LogarithmicFilterbank(frequencies).T #MelFilterbank(frequencies).T\n",
    "    mel_freq_bins = LogarithmicFilterbank(frequencies).center_frequencies #MelFilterbank(frequencies).center_frequencies\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(filterbank, interpolation=None, origin='lower', aspect='auto')\n",
    "    \n",
    "    #debug\n",
    "    #mel_idx = 39\n",
    "    #dbg.log(filterbank.shape, frequencies.shape)\n",
    "    #dbg.log(filterbank[39][filterbank[39] != 0 ])\n",
    "    #none_zero_idxs = np.where([filterbank[mel_idx] != 0 ])[1]\n",
    "    #dbg.log(none_zero_idxs)\n",
    "    #dbg.log(filterbank[mel_idx][none_zero_idxs])\n",
    "    \n",
    "    f_tick_idxs = np.arange(0, len(frequencies), int(len(frequencies)/8))\n",
    "    f_tick_lbls = [\"{:.1f}\".format(tick) for tick in frequencies[f_tick_idxs]]\n",
    "    mel_f_tick_idxs = np.append(np.arange(0, len(mel_freq_bins), 10), len(mel_freq_bins)-1)\n",
    "    mel_f_tick_lbls = [\"{:.1f}\".format(tick) for tick in mel_freq_bins[mel_f_tick_idxs]]\n",
    "    plt.xticks(f_tick_idxs, f_tick_lbls, rotation='45')\n",
    "    plt.yticks(mel_f_tick_idxs, mel_f_tick_lbls)\n",
    "    \n",
    "    plt.xlabel('Hertz scale');\n",
    "    plt.ylabel('Mel Scale');\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi)\n",
    "    \n",
    "plot_mel_scale(FIG_SIZE, DPI, get_fig_save_path('logarithmic_filterbank.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decibel Scale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
