{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities for Thesis\n",
    "### Figure generators and such"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import madmom\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "\n",
    "class Debugger:\n",
    "    def __init__(self, debug):\n",
    "        self.debug = debug\n",
    "        \n",
    "    def log(self, *msg):\n",
    "        if(self.debug):\n",
    "            print(msg)\n",
    "            \n",
    "dbg = Debugger(debug)\n",
    "dbg.log('debugger initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals Variables and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_FOLDER = 'utilities_for_thesis_figures'\n",
    "AUDIO_FILE_NAME = 'zztop_badtothebone_mono_5sec.wav'\n",
    "AUDIO_PATH_RELATIVE = '../../audio_for_thesis'\n",
    "\n",
    "FIG_SIZE = (9,6)\n",
    "DPI = 80\n",
    "\n",
    "assert os.path.exists(FIG_FOLDER), 'Folder doesnt exist: {}'.format(FIG_FOLDER)\n",
    "assert os.path.exists(AUDIO_PATH_RELATIVE), 'Folder doesnt exist: {}'.format(AUDIO_PATH_RELATIVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fig_save_path(fig_name):\n",
    "    return os.path.join(FIG_FOLDER, fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_len = 5\n",
    "\n",
    "audio_path = os.path.join(os.getcwd(), AUDIO_PATH_RELATIVE)\n",
    "audio_path_absolute = os.path.abspath(audio_path)\n",
    "assert os.path.exists(audio_path_absolute), 'Audio file path doesnt exist: {}'.format(audio_path_absolute)\n",
    "    \n",
    "audio_path_full = os.path.join(audio_path_absolute, AUDIO_FILE_NAME)\n",
    "assert os.path.exists(audio_path_full), 'Audio file doesnt exist: {}'.format(audio_path_full)\n",
    "\n",
    "fs, audio_buffer = wavfile.read(audio_path_full)\n",
    "\n",
    "assert fs == 44100, 'Sampling rate should be 44100 Hz'\n",
    "assert len(audio_buffer.shape) == 1, 'Audio should be mono'\n",
    "assert len(audio_buffer) == audio_len * fs, 'Audio should be exactly %d seconds long' %(audio_len)\n",
    "\n",
    "dbg.log(audio_path_full)\n",
    "dbg.log('audio buffer shape:', audio_buffer.shape, 'sampling rate:', fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Domain Audio Signal Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audio_buffer/audio_buffer.max())\n",
    "audio_ticks = np.arange(0, len(audio_buffer), fs/2)\n",
    "plt.xticks(audio_ticks, [\"{:.1f}\".format(tick/fs) for tick in audio_ticks], rotation='45')\n",
    "plt.xlim([0, len(audio_buffer)])\n",
    "plt.xlabel('Time (Seconds)')\n",
    "plt.ylabel('Amplitude (Normalized)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Domain Audio Signal Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Original:\n",
    "\n",
    "frame_size = 2048\n",
    "start_frame = 2*fs\n",
    "\n",
    "frame = audio_buffer[start_frame:start_frame+frame_size]\n",
    "spectrum = np.fft.fft(frame)\n",
    "\n",
    "abs_spec_size = int(frame_size/2+1)\n",
    "abs_spec = np.abs(spectrum)[:abs_spec_size]\n",
    "\n",
    "fft_freqs = np.fft.fftfreq(frame_size)*fs\n",
    "freq_ticks = np.arange(0, abs_spec_size, 128, dtype=int)\n",
    "freq_tick_labels = [\"{:.1f}Hz\".format(np.abs(fft_freqs[idx])) for idx in freq_ticks]\n",
    "print(fft_freqs[1024])\n",
    "\n",
    "\n",
    "plt.plot(abs_spec/abs_spec.max())\n",
    "plt.xticks(freq_ticks, freq_tick_labels, rotation=\"45\");\n",
    "'''\n",
    "\n",
    "frame_size = audio_len * fs # 220500\n",
    "\n",
    "frame = audio_buffer[0:frame_size] # take whole 5sec clip as frame\n",
    "spectrum = np.fft.fft(frame) # fft resolution is same as size of audio_buffer (220500)\n",
    "\n",
    "abs_spec_size = int(frame_size/2+1) # half cause mirrored (110251)\n",
    "abs_spec = np.abs(spectrum)[:abs_spec_size] # absolute values of half\n",
    "\n",
    "# frequency bin centers [0...0.5,-0.5...-0]\n",
    "# result in requency values when multiplied by sampling rate (cause same as resolution) (same as specifying d=1/sampling_rate)\n",
    "# with 220500 values\n",
    "# will only be used until index half, cause they are then mirrored in the negative\n",
    "fft_freqs = np.fft.fftfreq(frame_size)*fs\n",
    "dbg.log(fft_freqs[110250])\n",
    "\n",
    "# indices to be used, only go until 110251, cause of mirroring\n",
    "# 110251 / 7 = 15750.14, round down to get 8 indices instead of 7\n",
    "freq_ticks = np.arange(0, abs_spec_size, 15750, dtype=int)\n",
    "# labels (with Hz as value) for the corresponding indices\n",
    "freq_tick_labels = [\"{:.1f}\".format(np.abs(fft_freqs[idx])) for idx in freq_ticks]\n",
    "\n",
    "plt.plot(abs_spec/abs_spec.max())\n",
    "plt.xticks(freq_ticks, freq_tick_labels, rotation=\"45\")\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude / Power (Normalized)')\n",
    "\n",
    "dbg.log('spectrum resolution:', abs_spec.shape)\n",
    "dbg.log('fft frequencies:', fft_freqs.shape)\n",
    "dbg.log('indices to be used for freq. values:', freq_ticks)\n",
    "dbg.log('frequencies at above indices taken from fft frequencies:', freq_tick_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framing (frame size, hop size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_save_path = get_fig_save_path('signal_before_framing.png')\n",
    "\n",
    "frame_size = 128\n",
    "hop_size = 96\n",
    "frame_n = 3\n",
    "\n",
    "start_sample = int(0.5*fs)\n",
    "\n",
    "audio_segment = audio_buffer[start_sample: start_sample + ((frame_n-1)*(hop_size)) + frame_size]\n",
    "dbg.log(audio_segment.size)\n",
    "\n",
    "\n",
    "frames = []\n",
    "for i in range(0, frame_n):\n",
    "    start_curr = start_sample + i * hop_size\n",
    "    f = audio_buffer[start_curr: start_curr +  frame_size]\n",
    "    dbg.log(f.size)\n",
    "    frames.append(f)\n",
    "\n",
    "plt.figure(figsize=FIG_SIZE)\n",
    "plt.plot(audio_segment/audio_segment.max())\n",
    "\n",
    "audio_ticks = np.arange(0, audio_segment.size, int(audio_segment.size/9))\n",
    "plt.xticks(audio_ticks, [\"{:.0f}\".format(tick) for tick in audio_ticks], rotation='45')\n",
    "plt.xlim([0, audio_segment.size])\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Amplitude');\n",
    "\n",
    "plt.savefig(fig_save_path, dpi=DPI)\n",
    "\n",
    "x_axis_start, x_axis_end, y_axis_start, y_axis_end = plt.axis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1)\n",
    "\n",
    "for i in range(0, frame_n):\n",
    "    f = frames[i]\n",
    "    f_norm = f/audio_segment.max()\n",
    "    frame_in_segment = np.full(audio_segment.size, None)\n",
    "    frame_in_segment[i*hop_size :i*hop_size + f_norm.size] = f_norm\n",
    "        \n",
    "    ax[i].plot(frame_in_segment)\n",
    "    ax[i].axvspan(hop_size, hop_size + f.size, color='red', alpha=0.15)\n",
    "    \n",
    "    #ax[i].set_title('Frame {}'.format(i+1))\n",
    "        \n",
    "    if i == 2:\n",
    "        ax[i].set_xlabel('Sample')\n",
    "    ax[i].set_ylabel('Amplitude');\n",
    "    \n",
    "    ax[i].set_xlim([x_axis_start, x_axis_end])\n",
    "    ax[i].set_ylim([y_axis_start, y_axis_end])\n",
    "    \n",
    "    if i != 2:\n",
    "        ax[i].set_xticks([])\n",
    "    \n",
    "    if i == 2:\n",
    "        audio_ticks = np.arange(0, audio_segment.size, int(audio_segment.size/9))\n",
    "        ax[i].set_xticks(audio_ticks)\n",
    "        ax[i].set_xticklabels([\"{:.0f}\".format(tick) for tick in audio_ticks], rotation=45)\n",
    "        \n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.subplots_adjust(hspace=0.25)\n",
    "\n",
    "#plt.savefig('frames_split.png')\n",
    "plt.show()\n",
    "fig.savefig('frames_split.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = frames[0]\n",
    "plt.plot(f/audio_segment.max())\n",
    "audio_ticks = np.arange(0, f.size, int(f.size/8))\n",
    "plt.xticks(audio_ticks, [\"{:.0f}\".format(tick + (0*hop_size)) for tick in audio_ticks], rotation='45')\n",
    "plt.xlim([0, f.size])\n",
    "\n",
    "plt.ylim([y_axis_start, y_axis_end])\n",
    "\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Amplitude');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = frames[1]\n",
    "plt.plot(f/audio_segment.max())\n",
    "\n",
    "plt.axvspan(0, f.size, color='red', alpha=0.15)\n",
    "\n",
    "audio_ticks = np.arange(0, f.size, int(f.size/8))\n",
    "plt.xticks(audio_ticks, [\"{:.0f}\".format(tick + (1*hop_size)) for tick in audio_ticks], rotation='45')\n",
    "plt.xlim([0, f.size])\n",
    "\n",
    "plt.ylim([y_axis_start, y_axis_end])\n",
    "\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Amplitude');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = frames[2]\n",
    "plt.plot(f/audio_segment.max())\n",
    "audio_ticks = np.arange(0, f.size, int(f.size/8))\n",
    "plt.xticks(audio_ticks, [\"{:.0f}\".format(tick + (2*hop_size)) for tick in audio_ticks], rotation='45')\n",
    "plt.xlim([0, f.size])\n",
    "\n",
    "plt.ylim([y_axis_start, y_axis_end])\n",
    "\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Amplitude');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hann Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widnow function\n",
    "\n",
    "frame_size = 441\n",
    "sample_idxs = np.arange(0, frame_size)\n",
    "\n",
    "# 0 <= n <= N-1\n",
    "def hann(n, N):\n",
    "    return 0.5 * (1 - math.cos((2 * math.pi * n) / (N - 1)))\n",
    "\n",
    "v_hann = np.vectorize(hann)\n",
    "smoothing_coefficients = v_hann(sample_idxs, frame_size)\n",
    "\n",
    "plt.plot(smoothing_coefficients)\n",
    "\n",
    "x_ticks = np.arange(0, frame_size, 44, dtype=int)\n",
    "plt.xticks(x_ticks, rotation=\"45\")\n",
    "plt.xlim([0, frame_size])\n",
    "\n",
    "plt.xlabel('Sample');\n",
    "plt.ylabel('Smoothing Coefficient');\n",
    "\n",
    "dbg.log('sample values:', v_hann([0, 110 ,220 ,330 ,440], frame_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio frame (not smoothed)\n",
    "\n",
    "frame_start = int(0.5 * fs) # start at 0.5sec\n",
    "frame_end = frame_start + frame_size\n",
    "frame = audio_buffer[frame_start: frame_end]\n",
    "\n",
    "plt.plot(frame / frame.max())\n",
    "\n",
    "x_ticks = np.arange(0, frame_size, 44, dtype=int)\n",
    "plt.xticks(x_ticks, rotation=\"45\")\n",
    "plt.xlim([0, frame_size])\n",
    "\n",
    "plt.xlabel('Sample');\n",
    "plt.ylabel('Amplitude');\n",
    "\n",
    "x_axis_start, x_axis_end, y_axis_start, y_axis_end = plt.axis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio frame (smoothed)\n",
    "\n",
    "v_hann = np.vectorize(hann)\n",
    "smoothing_coefficients = v_hann(sample_idxs, frame_size)\n",
    "smoothed_frame = smoothing_coefficients * frame\n",
    "\n",
    "plt.plot(smoothed_frame / frame.max())\n",
    "\n",
    "x_ticks = np.arange(0, frame_size, 44, dtype=int)\n",
    "plt.xticks(x_ticks, rotation=\"45\")\n",
    "plt.xlim([x_axis_start, x_axis_end])\n",
    "\n",
    "y_ticks = np.arange(-1, 1.5, 0.5)\n",
    "plt.yticks(y_ticks)\n",
    "plt.ylim([y_axis_start, y_axis_end])\n",
    "\n",
    "plt.xlabel('Sample');\n",
    "plt.ylabel('Amplitude');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time/Frequency Domain Audio Signal Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decibel Scale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
