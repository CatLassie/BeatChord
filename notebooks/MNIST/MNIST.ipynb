{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "# import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "# model path\n",
    "CURRENT_PATH = os.getcwd()\n",
    "MODEL_PATH = os.path.join(CURRENT_PATH, 'models')\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)  \n",
    "    \n",
    "MODEL_NAME = 'model'\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CURRENT DEVICE:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK PARAMETERS\n",
    "\n",
    "# depth\n",
    "in_size = 1\n",
    "h1_size = 16\n",
    "h2_size = 32\n",
    "\n",
    "# kernel size\n",
    "k_conv_size = 5\n",
    "k_pool_size = 2\n",
    "\n",
    "# fully connected parameters\n",
    "fc_size = 512\n",
    "out_size = 10\n",
    "\n",
    "#number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# learning rate\n",
    "lr = 0.001\n",
    "\n",
    "# loss function\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES\n",
    "\n",
    "# import data\n",
    "mnist_train = pd.read_csv('../../../datasets/mnist_csv/mnist_train.csv')\n",
    "mnist_test = pd.read_csv('../../../datasets/mnist_csv/mnist_test.csv')\n",
    "\n",
    "# prepare data\n",
    "train = mnist_train.dropna()\n",
    "train_feat = mnist_train.drop('label', axis=1)\n",
    "train_target = mnist_train['label']\n",
    "\n",
    "test = mnist_test.dropna()\n",
    "test_feat = mnist_test.drop('label', axis=1)\n",
    "test_target = mnist_test['label']\n",
    "\n",
    "# convert to tensors\n",
    "train_f = torch.tensor(train_feat.values, dtype=torch.float)\n",
    "train_t = torch.tensor(train_target.values, dtype=torch.long)\n",
    "test_f = torch.tensor(test_feat.values, dtype=torch.float)\n",
    "test_t = torch.tensor(test_target.values, dtype=torch.long)\n",
    "train_f = train_f.reshape(-1,1,28,28)\n",
    "test_f = test_f.reshape(-1,1,28,28)\n",
    "print(train_f.shape)\n",
    "print(train_t.shape)\n",
    "print(test_f.shape)\n",
    "print(test_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK CLASS\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Conv2d(in_size, h1_size, k_conv_size),\n",
    "            nn.BatchNorm2d(h1_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = k_pool_size)\n",
    "        )\n",
    "        \n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Conv2d(h1_size, h2_size, k_conv_size),\n",
    "            nn.BatchNorm2d(h2_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = k_pool_size)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(fc_size, out_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out = self.l2(out)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL / OPTIMIZER INSTANCES, SETTING TO DEVICE\n",
    "\n",
    "# model\n",
    "model = ConvNet()\n",
    "\n",
    "# optimizer\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# to device\n",
    "model.to(device)\n",
    "train_f = train_f.to(device)\n",
    "train_t = train_t.to(device)\n",
    "test_f = test_f.to(device)\n",
    "test_t = test_t.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING FUNCTION\n",
    "\n",
    "def training():\n",
    "    # loss_values = list()\n",
    "\n",
    "    for epoch in range(1, num_epochs):\n",
    "\n",
    "        outputs = model(train_f)\n",
    "        loss = loss_func(outputs, train_t)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        print('Epoch - %d, loss - %0.5f '%(epoch, loss.item()))\n",
    "        # loss_values.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN AND SAVE MODEL\n",
    "# training()\n",
    "# torch.save(model.state_dict(), os.path.join(MODEL_PATH, MODEL_NAME + '.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL\n",
    "model = ConvNet().to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_PATH, MODEL_NAME + '.model')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    outputs = model(test_f)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    test_t_cpu = test_t.cpu().numpy()\n",
    "    predicted = predicted.cpu()\n",
    "    \n",
    "    print(\"Accuracy\", accuracy_score(predicted, test_t_cpu))\n",
    "    print(\"Precision\", precision_score(predicted, test_t_cpu, average='weighted'))\n",
    "    print(\"Recall\", recall_score(predicted, test_t_cpu, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
