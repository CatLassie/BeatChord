{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN Chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import madmom\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# configurations\n",
    "import scripts.tcn_chord_config as tcnc\n",
    "\n",
    "# feature, target, annotation initializer\n",
    "from scripts.tcn_chord_feat import init_data\n",
    "\n",
    "from scripts.chord_util import labels_to_notataion_and_intervals\n",
    "\n",
    "import mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "# random seed\n",
    "SEED = tcnc.SEED\n",
    "\n",
    "# cuda configuration\n",
    "USE_CUDA = tcnc.USE_CUDA\n",
    "DEVICE = tcnc.DEVICE\n",
    "print(\"CURRENT DEVICE:\", DEVICE)\n",
    "\n",
    "# paths\n",
    "MODEL_NAME = tcnc.MODEL_NAME\n",
    "MODEL_PATH = tcnc.MODEL_PATH\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)  \n",
    "    \n",
    "FPS = tcnc.FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING PARAMETERS\n",
    "\n",
    "num_epochs = tcnc.NUM_EPOCHS\n",
    "lr = tcnc.LR\n",
    "\n",
    "feature_context = tcnc.FEATURE_CONTEXT\n",
    "traininig_hop_size = tcnc.TRAINING_HOP_SIZE\n",
    "\n",
    "batch_size = tcnc.BATCH_SIZE\n",
    "patience = tcnc.PATIENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND LINE SUPPORT\n",
    "\n",
    "# TODO:\n",
    "\n",
    "TRAIN = tcnc.TRAIN\n",
    "TRAIN_EXISTING = tcnc.TRAIN_EXISTING\n",
    "PREDICT = tcnc.PREDICT\n",
    "VERBOSE = tcnc.VERBOSE\n",
    "\n",
    "if VERBOSE:\n",
    "    print('\\n---- EXECUTION STARTED ----\\n')\n",
    "    print('Train:', TRAIN)\n",
    "    print('Train existing model:', TRAIN_EXISTING)\n",
    "    print('Predict', PREDICT)\n",
    "    # print('Command line arguments:\\n\\n', args, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD FEATURES AND ANNOTATIONS, COMPUTE TARGETS\n",
    "train_f, train_t, train_anno, valid_f, valid_t, valid_anno, test_f, test_t, test_anno = init_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK PARAMETERS\n",
    "\n",
    "# CNN\n",
    "\n",
    "LAST_CNN_KERNEL_FREQUENCY_SIZE = tcnc.LAST_CNN_KERNEL_FREQUENCY_SIZE\n",
    "\n",
    "# filters\n",
    "cnn_in_size = 1\n",
    "cnn_h_size = 16\n",
    "\n",
    "# kernels\n",
    "cnn_k_1_size = 3\n",
    "cnn_k_2_size = (1, LAST_CNN_KERNEL_FREQUENCY_SIZE)\n",
    "cnn_padding = (1,0)\n",
    "cnn_max_pool_k_size = (1,3)\n",
    "\n",
    "cnn_dropout_rate = 0.1\n",
    "\n",
    "# TCN\n",
    "\n",
    "tcn_layer_num = 8 #11\n",
    "\n",
    "# filters\n",
    "tcn_h_size = 16\n",
    "\n",
    "# kernels\n",
    "tcn_k_size = 5\n",
    "tcn_dilations = [2**x for x in range(0, tcn_layer_num)]\n",
    "tcn_paddings = [2*x for x in tcn_dilations]\n",
    "\n",
    "tcn_dropout_rate = 0.1\n",
    "\n",
    "# FULLY CONNECTED (by using a 1d convolutional. layer)\n",
    "\n",
    "# filters\n",
    "fc_h_size = 16\n",
    "fc_out_size = 13\n",
    "\n",
    "# kernels\n",
    "fc_k_size = 1\n",
    "\n",
    "# loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "unseen_loss_func = nn.CrossEntropyLoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEAT NETWORK CLASS and DATA SET CLASS for DATA LOADER\n",
    "\n",
    "class TCNChordNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TCNChordNet, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Conv2d(cnn_in_size, cnn_h_size, cnn_k_1_size, padding=cnn_padding),\n",
    "            nn.BatchNorm2d(cnn_h_size),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size = cnn_max_pool_k_size),\n",
    "            nn.Dropout2d(p = cnn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Conv2d(cnn_h_size, cnn_h_size, cnn_k_1_size, padding=cnn_padding),\n",
    "            nn.BatchNorm2d(cnn_h_size),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size = cnn_max_pool_k_size),\n",
    "            nn.Dropout2d(p = cnn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.l3 = nn.Sequential(\n",
    "            nn.Conv2d(cnn_h_size, cnn_h_size, cnn_k_2_size),\n",
    "            # nn.BatchNorm2d(cnn_h_size), # cant use because spec is reduced to 1x1\n",
    "            # NOTE: if needed try Instance normalization (InstanceNorm2d)\n",
    "            nn.ELU(),\n",
    "            nn.Dropout2d(p = cnn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld1 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[0], dilation=tcn_dilations[0]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld2 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[1], dilation=tcn_dilations[1]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld3 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[2], dilation=tcn_dilations[2]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld4 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[3], dilation=tcn_dilations[3]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld5 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[4], dilation=tcn_dilations[4]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld6 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[5], dilation=tcn_dilations[5]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld7 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[6], dilation=tcn_dilations[6]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld8 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[7], dilation=tcn_dilations[7]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.lfc = nn.Sequential(\n",
    "            nn.Conv1d(fc_h_size, fc_out_size, fc_k_size),\n",
    "            # nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        out = self.l1(x)\n",
    "        # print(out.shape)\n",
    "\n",
    "        out = self.l2(out)\n",
    "        # print(out.shape)\n",
    "\n",
    "        out = self.l3(out)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out.squeeze_(-1)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out = self.ld1(out)\n",
    "        out = self.ld2(out)\n",
    "        out = self.ld3(out)\n",
    "        out = self.ld4(out)\n",
    "        out = self.ld5(out)\n",
    "        out = self.ld6(out)\n",
    "        out = self.ld7(out)\n",
    "        out = self.ld8(out)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out = self.lfc(out)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out = out.squeeze(1)\n",
    "        # print(out.shape)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "# Dataset for DataLoader (items are pairs of Context x 81 (time x freq.) spectrogram snippets and 0-1 (0.5) target values)\n",
    "class TCNChordSet(Dataset):\n",
    "    def __init__(self, feat_list, targ_list, context, hop_size):\n",
    "        self.features = feat_list\n",
    "        self.targets = targ_list\n",
    "        self.context = context\n",
    "        self.hop_size = hop_size\n",
    " \n",
    "        # list with snippet count per track\n",
    "        self.snip_cnt = []\n",
    "        # overall snippet count\n",
    "        total_snip_cnt = 0\n",
    "        # calculate overall number of snippets we can get from our data\n",
    "        for feat in feat_list:\n",
    "            if feat.shape[0]- self.context >= 0: # !!! WARNING: was > previously !!!\n",
    "                cur_len = int(np.floor((feat.shape[0] - self.context)/hop_size) + 1)\n",
    "                self.snip_cnt.append(cur_len)\n",
    "                total_snip_cnt += cur_len\n",
    "            else:\n",
    "                cur_len = 0\n",
    "                self.snip_cnt.append(cur_len)\n",
    "                total_snip_cnt += cur_len \n",
    "                print(\"warning: skipped 1 example, shape\", feat.shape[0])\n",
    "\n",
    "        self.length = int(total_snip_cnt)\n",
    "        super(TCNChordSet, self).__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # find track which contains snippet with index [index]\n",
    "        overal_pos = 0\n",
    "        for idx, cnt in enumerate(self.snip_cnt):\n",
    "            # check if this track contains the snippet with index [index]\n",
    "            if index < overal_pos+cnt:\n",
    "                break\n",
    "            else:\n",
    "                # if not, add the current tracks snippet count to the overall snippet count already visited\n",
    "                overal_pos += cnt\n",
    "\n",
    "        # calculate the position of the snippet within the track nr. [idx]\n",
    "        position = index-overal_pos\n",
    "        position *= self.hop_size\n",
    "\n",
    "        # get snippet and target\n",
    "        \n",
    "        sample = self.features[idx][position : position+self.context]\n",
    "        target = self.targets[idx][position : position+self.context]\n",
    "        # convert to PyTorch tensor and return (unsqueeze is for extra dimension, asarray is cause target is scalar)\n",
    "        return torch.from_numpy(sample).unsqueeze_(0), torch.from_numpy(np.asarray(target))\n",
    "\n",
    "\n",
    "\n",
    "# helper class for arguments\n",
    "class Args:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN / TEST / PREDICT\n",
    "\n",
    "def train_one_epoch(args, model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Training for one epoch.\n",
    "    \"\"\"\n",
    "    # set model to training mode (activate dropout / batch normalization).\n",
    "    model.train()\n",
    "    t = time.time()\n",
    "    # iterate through all data using the loader\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # move data to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # reset optimizer (clear previous gradients)\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass (calculate output of network for input)\n",
    "        output = model(data.float())\n",
    "        # calculate loss        \n",
    "        loss = loss_func(output, target)\n",
    "        # do a backward pass (calculate gradients using automatic differentiation and backpropagation)\n",
    "        loss.backward()\n",
    "        # udpate parameters of network using calculated gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print logs\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, took {:.2f}s'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), time.time()-t))\n",
    "            t = time.time()\n",
    "\n",
    "        # WORK IN PROGRESS: skip rest of loop\n",
    "        # print('train batch index:', batch_idx)\n",
    "        # break\n",
    "       \n",
    "def calculate_unseen_loss(model, device, unseen_loader):\n",
    "    \"\"\"\n",
    "    Calculate loss for unseen data (validation or testing)\n",
    "    :return: cumulative loss\n",
    "    \"\"\"\n",
    "    # set model to inference mode (deactivate dropout / batch normalization).\n",
    "    model.eval()\n",
    "    # init cumulative loss\n",
    "    unseen_loss = 0\n",
    "    # no gradient calculation    \n",
    "    with torch.no_grad():\n",
    "        # iterate over test data\n",
    "        for data, target in unseen_loader:\n",
    "            # move data to device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # forward pass (calculate output of network for input)\n",
    "            output = model(data.float())\n",
    "            \n",
    "            # WORK IN PROGRESS: skip rest of loop\n",
    "            # continue\n",
    "            \n",
    "            # claculate loss and add it to our cumulative loss\n",
    "            unseen_loss += unseen_loss_func(output, target).item() # sum up batch loss\n",
    "\n",
    "    # output results of test run\n",
    "    unseen_loss /= len(unseen_loader.dataset)\n",
    "    print('Average loss: {:.4f}\\n'.format(\n",
    "        unseen_loss, len(unseen_loader.dataset)))\n",
    "\n",
    "    return unseen_loss\n",
    "  \n",
    "    \n",
    "    \n",
    "def predict(model, device, data, context):\n",
    "    \"\"\"\n",
    "    Predict beat\n",
    "    :return: prediction\n",
    "    \"\"\"\n",
    "    # set model to inference mode (deactivate dropout / batch normalization).\n",
    "    model.eval()\n",
    "    output = None\n",
    "    # move data to device\n",
    "    data = torch.from_numpy(data[None, None, :, :])\n",
    "    data = data.to(device)\n",
    "    # no gradient calculation\n",
    "    with torch.no_grad():\n",
    "        output = model(data.float())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    print('Training network...')\n",
    "\n",
    "    # parameters for NN training\n",
    "    args = Args()\n",
    "    args.batch_size = batch_size #1 #64\n",
    "    args.max_epochs = num_epochs #25 #1000\n",
    "    args.patience = patience #4\n",
    "    args.lr = lr # 0.001, 0.0001\n",
    "    args.momentum = 0.5 #UNUSED\n",
    "    args.log_interval = 100 #100\n",
    "    args.context = feature_context #5\n",
    "    args.hop_size = traininig_hop_size\n",
    "\n",
    "    # setup pytorch\n",
    "    torch.manual_seed(SEED)\n",
    "    \n",
    "    # create model and optimizer\n",
    "    model = TCNChordNet().to(DEVICE)\n",
    "    if TRAIN_EXISTING:\n",
    "        model.load_state_dict(torch.load(os.path.join(MODEL_PATH, MODEL_NAME + '.model')))\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # setup our datasets for training, evaluation and testing\n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True} if USE_CUDA else {'num_workers': 4}\n",
    "    train_loader = torch.utils.data.DataLoader(TCNChordSet(train_f, train_t, args.context, args.hop_size),\n",
    "                                               batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    valid_loader = torch.utils.data.DataLoader(TCNChordSet(valid_f, valid_t, args.context, args.hop_size),\n",
    "                                               batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(TCNChordSet(test_f, test_t, args.context, args.hop_size),\n",
    "                                              batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    # main training loop\n",
    "    best_validation_loss = 9999\n",
    "    cur_patience = args.patience\n",
    "    for epoch in range(1, args.max_epochs + 1):\n",
    "        # run one epoch of NN training\n",
    "        train_one_epoch(args, model, DEVICE, train_loader, optimizer, epoch)\n",
    "        \n",
    "        # WORK IN PROGRESS: \n",
    "        # return\n",
    "        \n",
    "        # validate on validation set\n",
    "        print('\\nValidation Set:')\n",
    "        validation_loss = calculate_unseen_loss(model, DEVICE, valid_loader)\n",
    "        # check for early stopping\n",
    "        if validation_loss < best_validation_loss:\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_PATH, MODEL_NAME + '.model'))\n",
    "            best_validation_loss = validation_loss\n",
    "            cur_patience = args.patience\n",
    "        else:\n",
    "            # if performance does not improve, we do not stop immediately but wait for 4 iterations (patience)\n",
    "            if cur_patience <= 0:\n",
    "                print('Early stopping, no improvement for %d epochs...' % args.patience)\n",
    "                break\n",
    "            else:\n",
    "                print('No improvement, patience: %d' % cur_patience)\n",
    "                cur_patience -= 1\n",
    "\n",
    "    # testing on test data\n",
    "    print('Evaluate network...')\n",
    "    print('Test Set:')\n",
    "    # calculate loss for test set\n",
    "    calculate_unseen_loss(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN or TRAIN_EXISTING:\n",
    "    run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(test_features): \n",
    "    args = Args()\n",
    "    args.context = feature_context #5\n",
    "    \n",
    "    torch.manual_seed(SEED)\n",
    "    \n",
    "    # load model\n",
    "    model = TCNChordNet().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(os.path.join(MODEL_PATH, MODEL_NAME + '.model')))\n",
    "    print('model loaded...')\n",
    "    \n",
    "    # calculate actual output for the test data\n",
    "    results_cnn = [None for _ in range(len(test_features))]\n",
    "    # iterate over test tracks\n",
    "    for test_idx, cur_test_feat in enumerate(test_features):\n",
    "        if test_idx % 100 == 0:\n",
    "            completion = int((test_idx / len(test_features))*100)\n",
    "            print(str(completion)+'% complete...')\n",
    "        if VERBOSE:\n",
    "            print('file number:', test_idx+1)\n",
    "        \n",
    "        # run the inference method\n",
    "        result = predict(model, DEVICE, cur_test_feat, args.context)\n",
    "        results_cnn[test_idx] = result #.cpu().numpy()\n",
    "\n",
    "    return results_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = None\n",
    "\n",
    "if PREDICT:\n",
    "    # predict chords\n",
    "    if VERBOSE:\n",
    "        print('predicting...')\n",
    "    predicted = run_prediction(test_f) #[test_t[0], test_t[1]]\n",
    "                    \n",
    "    # evaluate results\n",
    "    if VERBOSE:\n",
    "        print('evaluating results...')\n",
    "        \n",
    "    p_scores_mic = []\n",
    "    r_scores_mic = []\n",
    "    f1_scores_mic = []\n",
    "    p_scores_w = []\n",
    "    r_scores_w = []\n",
    "    f1_scores_w = []\n",
    "    \n",
    "    weighted_accuracies = []\n",
    "    \n",
    "    for i, pred_chord in enumerate(predicted):        \n",
    "        \n",
    "        # pred_chord = pred_chord.squeeze(0) # squeeze cause the dimensions are (1, frame_num, cause of the batch)!!!\n",
    "        \n",
    "        p_scores_mic.append(precision_score(test_t[i], pred_chord, average='micro'))\n",
    "        r_scores_mic.append(recall_score(test_t[i], pred_chord, average='micro'))\n",
    "        f1_scores_mic.append(f1_score(test_t[i], pred_chord, average='micro'))\n",
    "\n",
    "        p_scores_w.append(precision_score(test_t[i], pred_chord, average='weighted'))\n",
    "        r_scores_w.append(recall_score(test_t[i], pred_chord, average='weighted'))\n",
    "        f1_scores_w.append(f1_score(test_t[i], pred_chord, average='weighted'))\n",
    "        \n",
    "        # mir_eval score (weighted accuracy)\n",
    "\n",
    "        ref_labels, ref_intervals = labels_to_notataion_and_intervals(test_t[i])\n",
    "        est_labels, est_intervals = labels_to_notataion_and_intervals(pred_chord)\n",
    "\n",
    "        est_intervals, est_labels = mir_eval.util.adjust_intervals(\n",
    "            est_intervals, est_labels, ref_intervals.min(),\n",
    "            ref_intervals.max(), mir_eval.chord.NO_CHORD,\n",
    "            mir_eval.chord.NO_CHORD)\n",
    "\n",
    "        # print('label length before merge', len(ref_labels), len(est_labels))\n",
    "        # print('interval length before merge', len(ref_intervals), len(est_intervals))\n",
    "        merged_intervals, ref_labels, est_labels = mir_eval.util.merge_labeled_intervals(ref_intervals, ref_labels, est_intervals, est_labels)\n",
    "        # print('label length after merge', len(ref_labels), len(est_labels))\n",
    "        # print('interval length after merge', len(merged_intervals))\n",
    "\n",
    "        durations = mir_eval.util.intervals_to_durations(merged_intervals)\n",
    "        comparison = mir_eval.chord.root(ref_labels, est_labels)\n",
    "        score = mir_eval.chord.weighted_accuracy(comparison, durations)\n",
    "\n",
    "        weighted_accuracies.append(score)\n",
    "    \n",
    "    print('Precision (micro):', np.mean(p_scores_mic))\n",
    "    print('Recall (mico):', np.mean(r_scores_mic))\n",
    "    print('F-measure (micro):', np.mean(f1_scores_mic))\n",
    "    \n",
    "    print('Precision (weighted):', np.mean(p_scores_w))\n",
    "    print('Recall (weighted):', np.mean(r_scores_w))\n",
    "    print('F-measure (weighted):', np.mean(f1_scores_w))\n",
    "    \n",
    "    print('Weighted accuracies (mir_eval):', np.mean(weighted_accuracies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
