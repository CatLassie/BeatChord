{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beat SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import madmom\n",
    "from madmom.utils import search_files\n",
    "from madmom.features.onsets import OnsetPeakPickingProcessor\n",
    "# from madmom.features.beats import BeatTrackingProcessor\n",
    "from madmom.evaluation.beats import BeatEvaluation\n",
    "from madmom.evaluation.beats import BeatMeanEvaluation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import importlib\n",
    "bsc = importlib.import_module(\"beat-sota-config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "# random seed\n",
    "SEED = bsc.SEED\n",
    "\n",
    "# cuda configuration\n",
    "USE_CUDA = bsc.USE_CUDA\n",
    "DEVICE = bsc.DEVICE\n",
    "print(\"CURRENT DEVICE:\", DEVICE)\n",
    "\n",
    "# paths\n",
    "MODEL_NAME = bsc.MODEL_NAME\n",
    "MODEL_PATH = bsc.MODEL_PATH\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)  \n",
    "    \n",
    "FEATURE_EXT = bsc.FEATURE_EXT\n",
    "FEATURE_PATH = bsc.FEATURE_PATH\n",
    "ANNOTATION_EXT = bsc.ANNOTATION_EXT\n",
    "ANNOTATION_PATH = bsc.ANNOTATION_PATH\n",
    "\n",
    "FPS = bsc.FPS\n",
    "\n",
    "TRAIN_SPLIT_POINT = bsc.TRAIN_SPLIT_POINT\n",
    "VALIDATION_SPLIT_POINT = bsc.VALIDATION_SPLIT_POINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING PARAMETERS\n",
    "\n",
    "num_epochs = bsc.NUM_EPOCHS\n",
    "\n",
    "lr = bsc.LR\n",
    "\n",
    "feature_context = bsc.FEATURE_CONTEXT\n",
    "traininig_hop_size = bsc.TRAINING_HOP_SIZE\n",
    "\n",
    "batch_size = bsc.BATCH_SIZE\n",
    "patience = bsc.PATIENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND LINE SUPPORT\n",
    "\n",
    "# TODO:\n",
    "\n",
    "TRAIN = bsc.TRAIN\n",
    "PREDICT = bsc.PREDICT\n",
    "ZERO_PAD = bsc.ZERO_PAD\n",
    "VERBOSE = bsc.VERBOSE\n",
    "COMPLETE_DISPLAY_INTERVAL = bsc.COMPLETE_DISPLAY_INTERVAL\n",
    "\n",
    "if VERBOSE:\n",
    "    print('\\n---- EXECUTION STARTED ----\\n')\n",
    "    # print('Command line arguments:\\n\\n', args, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETION DISPLAY\n",
    "CURRENT_MOD = 1\n",
    "CURRENT_LENGTH = 1\n",
    "COMPLETE_DIVISOR  = int(100 / COMPLETE_DISPLAY_INTERVAL)\n",
    "\n",
    "def set_current_display(element_num):\n",
    "    global CURRENT_MOD\n",
    "    global CURRENT_LENGTH\n",
    "    \n",
    "    CURRENT_MOD = int(element_num / COMPLETE_DIVISOR) or 1\n",
    "    CURRENT_LENGTH = element_num\n",
    "    \n",
    "def display_progress(idx):\n",
    "    if idx % CURRENT_MOD == 0:\n",
    "        print(str(int((idx / CURRENT_LENGTH)*100)) + '%', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS FOR FEATURES AND TARGETS\n",
    "\n",
    "# compute a target array for 1 feature (1 (0.5 on neighbouring frames) for beat, 0 for non-beat in each frame)\n",
    "# NOTE: if there is an annotation that is after the last frame, ignore it\n",
    "\n",
    "def zero_pad_short_features(feat_list):\n",
    "    # 0 pad features to start from frame 1\n",
    "    feat_list_padded = []\n",
    "    for feat in feat_list:\n",
    "\n",
    "        if len(feat) < feature_context:\n",
    "            diff = feature_context - len(feat)\n",
    "            left = int(np.floor(diff/2))\n",
    "            right = int(np.ceil(diff/2))\n",
    "            \n",
    "            feat_padded = np.zeros((feat.shape[0] + diff, feat.shape[1]), np.float32)\n",
    "            feat_padded[left : feat.shape[0] + left, : feat.shape[1]] = feat\n",
    "            feat_list_padded.append(feat_padded)\n",
    "        else:\n",
    "            feat_list_padded.append(feat)\n",
    "            \n",
    "    return feat_list_padded\n",
    "\n",
    "def zero_pad_short_targets(target_list):\n",
    "    # 0 pad targets to start from frame 1\n",
    "    target_list_padded = []\n",
    "    for target in target_list:\n",
    "\n",
    "        if len(target) < feature_context:\n",
    "            diff = feature_context - len(target)\n",
    "            left = int(np.floor(diff/2))\n",
    "            right = int(np.ceil(diff/2))\n",
    "            \n",
    "            target_padded = np.zeros((target.shape[0] + diff), np.float32)\n",
    "            target_padded[left : target.shape[0] + left] = target\n",
    "            target_list_padded.append(target_padded)\n",
    "        else:\n",
    "            target_list_padded.append(target)\n",
    "            \n",
    "    return target_list_padded\n",
    "\n",
    "def compute_target(times, num_frames):\n",
    "    \"\"\"\n",
    "    if len(times) > 0 and np.max(times) * FPS > num_frames and VERBOSE:\n",
    "        print(\"Maximum time is larger than number of samples - cutting times.\")\n",
    "        print(np.max(times)*FPS, num_frames)\n",
    "    \"\"\"\n",
    "\n",
    "    target = np.zeros(num_frames, np.float32)\n",
    "    for idx, time in enumerate(times):\n",
    "        time_idx = int(np.rint(time*FPS))\n",
    "        if time_idx < num_frames:\n",
    "            target[time_idx] = 1\n",
    "            \n",
    "            # for 0.5 probabilities on either side of beat frame\n",
    "            if(time_idx > 0):\n",
    "                target[time_idx-1] = 0.5\n",
    "            if(time_idx < (num_frames-1)):\n",
    "                target[time_idx+1] = 0.5\n",
    "\n",
    "    return target\n",
    "\n",
    "def init_targets(annos, feats):\n",
    "    targs = []\n",
    "    for anno, feat in zip(annos, feats):\n",
    "        targ = compute_target(anno, len(feat)) # time axis for length!\n",
    "        targs.append(targ)\n",
    "    return targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD FEATURES AND ANNOTATIONS, COMPUTE TARGETS\n",
    "\n",
    "# load and initialize feature data\n",
    "feat_paths = search_files(FEATURE_PATH, FEATURE_EXT)\n",
    "anno_paths = search_files(ANNOTATION_PATH, ANNOTATION_EXT)\n",
    "\n",
    "features = [np.load(p) for p in feat_paths]\n",
    "# librosa has time in rows, madmom is transposed! now first index is time as in madmom!\n",
    "features = [np.transpose(f) for f in features]\n",
    "annotations = [madmom.io.load_beats(p) for p in anno_paths]\n",
    "targets = init_targets(annotations, features)\n",
    "\n",
    "assert len(features) == len(targets)\n",
    "\n",
    "\n",
    "######## 0 pad features that are shorter than 8193 frames ########\n",
    "\n",
    "if ZERO_PAD:\n",
    "    features = zero_pad_short_features(features)\n",
    "    targets = zero_pad_short_targets(targets)\n",
    "\n",
    "######## (optionally FILTER SHORTER THAN 10 SEC TRACKS) and SHUFFLE ########\n",
    "\n",
    "# get sort indices by length\n",
    "feture_lengths = [len(x) for x in features]\n",
    "sort_idxs = np.argsort(feture_lengths)\n",
    "\n",
    "# sort by feature length\n",
    "features_sort = [features[i] for i in sort_idxs]\n",
    "targets_sort = [targets[i] for i in sort_idxs]\n",
    "annotations_sort = [annotations[i] for i in sort_idxs]\n",
    "\n",
    "   ######## optionally filter out tracks of length less than <length> ########\n",
    "# filter out 12 shortes tracks (>10sec)\n",
    "# features_sort = features_sort[12:]\n",
    "# targets_sort = targets_sort[12:]\n",
    "# annotations_sort = annotations_sort[12:]\n",
    "   ###########################################################################\n",
    "\n",
    "# print(sort_idxs)\n",
    "# print(features_sort[164][0][:5])\n",
    "# print(targets_sort[164][:50])\n",
    "# print(annotations_sort[164][:5])\n",
    "\n",
    "print('shortest track is:', len(features_sort[0]), 'frames at', FPS, 'FPS')\n",
    "print('longest track is:', len(features_sort[len(features_sort)-1]), 'frames at', FPS, 'FPS')\n",
    "\n",
    "# get sort indices by length again\n",
    "feture_lengths = [len(x) for x in features_sort]\n",
    "sort_idxs = np.argsort(feture_lengths)\n",
    "\n",
    "# shuffle indices\n",
    "random.seed(SEED)\n",
    "random.shuffle(sort_idxs)\n",
    "\n",
    "# shuffle data\n",
    "features_rand = [features_sort[i] for i in sort_idxs]\n",
    "targets_rand = [targets_sort[i] for i in sort_idxs]\n",
    "annotations_rand = [annotations_sort[i] for i in sort_idxs]\n",
    "\n",
    "# print(sort_idxs)\n",
    "# print(features_rand[31][0][:5])\n",
    "# print(targets_rand[31][:50])\n",
    "# print(annotations_rand[31][:5])\n",
    "\n",
    "###############################################################\n",
    "\n",
    "\n",
    "\n",
    "first_idx = int(len(features_rand)*TRAIN_SPLIT_POINT)\n",
    "second_idx = int(len(features_rand)*VALIDATION_SPLIT_POINT)\n",
    "\n",
    "train_f = features_rand[: first_idx]\n",
    "train_t = targets_rand[: first_idx]\n",
    "valid_f = features_rand[first_idx : second_idx]\n",
    "valid_t = targets_rand[first_idx : second_idx]\n",
    "test_f = features_rand[second_idx :]\n",
    "test_t = targets_rand[second_idx :]\n",
    "\n",
    "train_anno = annotations_rand[: first_idx]\n",
    "valid_anno = annotations_rand[first_idx : second_idx]\n",
    "test_anno = annotations_rand[second_idx :]\n",
    "\n",
    "if VERBOSE:\n",
    "    print(len(features_rand), 'feature spectrogram files loaded, with example shape:', features_rand[0].shape)\n",
    "    print(len(annotations_rand), 'feature annotation files loaded, with example shape:', annotations_rand[0].shape)\n",
    "    print(len(targets_rand), 'targets computed, with example shape:', targets_rand[0].shape)\n",
    "    print(len(train_f), 'training features', len(valid_f), 'validation features and', len(test_f), 'test features')\n",
    "  \n",
    "# Conacatenate spectrograms along the time axis\n",
    "# features = np.concatenate(features, axis=1)\n",
    "# print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK PARAMETERS\n",
    "\n",
    "# CNN\n",
    "\n",
    "# filters\n",
    "cnn_in_size = 1\n",
    "cnn_h_size = 16\n",
    "\n",
    "# kernels\n",
    "cnn_k_1_size = 3\n",
    "cnn_k_2_size = (1, 8)\n",
    "cnn_padding = (1,0)\n",
    "cnn_max_pool_k_size = (1,3)\n",
    "\n",
    "cnn_dropout_rate = 0.1\n",
    "\n",
    "# TCN\n",
    "\n",
    "tcn_layer_num = 11 #7\n",
    "\n",
    "# filters\n",
    "tcn_h_size = 16\n",
    "\n",
    "# kernels\n",
    "tcn_k_size = 5\n",
    "tcn_dilations = [2**x for x in range(0, tcn_layer_num)]\n",
    "tcn_paddings = [2*x for x in tcn_dilations]\n",
    "\n",
    "tcn_dropout_rate = 0.1\n",
    "\n",
    "# FULLY CONNECTED (by using a 1d convolutional. layer)\n",
    "\n",
    "# filters\n",
    "fc_h_size = 16\n",
    "fc_out_size = 1\n",
    "\n",
    "# kernels\n",
    "fc_k_size = 1\n",
    "\n",
    "# alternatively a dense layer with in size 8193*16 and out size 1 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEAT NETWORK CLASS and DATA SET CLASS for DATA LOADER\n",
    "\n",
    "class BeatNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BeatNet, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Conv2d(cnn_in_size, cnn_h_size, cnn_k_1_size, padding=cnn_padding),\n",
    "            nn.BatchNorm2d(cnn_h_size),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size = cnn_max_pool_k_size),\n",
    "            nn.Dropout2d(p = cnn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Conv2d(cnn_h_size, cnn_h_size, cnn_k_1_size, padding=cnn_padding),\n",
    "            nn.BatchNorm2d(cnn_h_size),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size = cnn_max_pool_k_size),\n",
    "            nn.Dropout2d(p = cnn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.l3 = nn.Sequential(\n",
    "            nn.Conv2d(cnn_h_size, cnn_h_size, cnn_k_2_size),\n",
    "            # nn.BatchNorm2d(cnn_h_size), # cant use because spec is reduced to 1x1\n",
    "            # NOTE: if needed try Instance normalization (InstanceNorm2d)\n",
    "            nn.ELU(),\n",
    "            nn.Dropout2d(p = cnn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld1 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[0], dilation=tcn_dilations[0]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld2 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[1], dilation=tcn_dilations[1]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld3 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[2], dilation=tcn_dilations[2]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld4 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[3], dilation=tcn_dilations[3]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld5 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[4], dilation=tcn_dilations[4]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld6 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[5], dilation=tcn_dilations[5]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld7 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[6], dilation=tcn_dilations[6]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld8 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[7], dilation=tcn_dilations[7]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld9 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[8], dilation=tcn_dilations[8]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld10 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[9], dilation=tcn_dilations[9]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld11 = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=tcn_paddings[10], dilation=tcn_dilations[10]),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.lfc = nn.Sequential(\n",
    "            nn.Conv1d(fc_h_size, fc_out_size, fc_k_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        out = self.l1(x)\n",
    "        # print(out.shape)\n",
    "\n",
    "        out = self.l2(out)\n",
    "        # print(out.shape)\n",
    "\n",
    "        out = self.l3(out)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out.squeeze_(-1)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out = self.ld1(out)\n",
    "        out = self.ld2(out)\n",
    "        out = self.ld3(out)\n",
    "        out = self.ld4(out)\n",
    "        out = self.ld5(out)\n",
    "        out = self.ld6(out)\n",
    "        out = self.ld7(out)\n",
    "        out = self.ld8(out)\n",
    "        out = self.ld9(out)\n",
    "        out = self.ld10(out)\n",
    "        out = self.ld11(out)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out = self.lfc(out)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out = out.squeeze(1)\n",
    "        # print(out.shape)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "# Dataset for DataLoader (items are pairs of Context x 81 (time x freq.) spectrogram snippets and 0-1 (0.5) target values)\n",
    "class BeatSet(Dataset):\n",
    "    def __init__(self, feat_list, targ_list, context, hop_size):\n",
    "        self.features = feat_list\n",
    "        self.targets = targ_list\n",
    "        self.context = context\n",
    "        self.hop_size = hop_size\n",
    " \n",
    "        # list with snippet count per track\n",
    "        self.snip_cnt = []\n",
    "        # overall snippet count\n",
    "        total_snip_cnt = 0\n",
    "        # calculate overall number of snippets we can get from our data\n",
    "        for feat in feat_list:\n",
    "            if feat.shape[0]- self.context >= 0: # !!! WARNING: was > previously !!!\n",
    "                cur_len = int(np.floor((feat.shape[0] - self.context)/hop_size) + 1)\n",
    "                self.snip_cnt.append(cur_len)\n",
    "                total_snip_cnt += cur_len\n",
    "            else:\n",
    "                cur_len = 0\n",
    "                self.snip_cnt.append(cur_len)\n",
    "                total_snip_cnt += cur_len \n",
    "                print(\"warning: skipped 1 example, shape\", feat.shape[0])\n",
    "\n",
    "        self.length = int(total_snip_cnt)\n",
    "        super(BeatSet, self).__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # find track which contains snippet with index [index]\n",
    "        overal_pos = 0\n",
    "        for idx, cnt in enumerate(self.snip_cnt):\n",
    "            # check if this track contains the snippet with index [index]\n",
    "            if index < overal_pos+cnt:\n",
    "                break\n",
    "            else:\n",
    "                # if not, add the current tracks snippet count to the overall snippet count already visited\n",
    "                overal_pos += cnt\n",
    "\n",
    "        # calculate the position of the snippet within the track nr. [idx]\n",
    "        position = index-overal_pos\n",
    "        position *= self.hop_size\n",
    "\n",
    "        # get snippet and target\n",
    "        \n",
    "        sample = self.features[idx][position : position+self.context]\n",
    "        target = self.targets[idx][position : position+self.context]\n",
    "        # convert to PyTorch tensor and return (unsqueeze is for extra dimension, asarray is cause target is scalar)\n",
    "        return torch.from_numpy(sample).unsqueeze_(0), torch.from_numpy(np.asarray(target))\n",
    "\n",
    "\n",
    "\n",
    "# helper class for arguments\n",
    "class Args:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN / TEST / PREDICT\n",
    "\n",
    "def train_one_epoch(args, model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Training for one epoch.\n",
    "    \"\"\"\n",
    "    # set model to training mode (activate dropout / batch normalization).\n",
    "    model.train()\n",
    "    t = time.time()\n",
    "    # iterate through all data using the loader\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # move data to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # reset optimizer (clear previous gradients)\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass (calculate output of network for input)\n",
    "        output = model(data.float())\n",
    "        # calculate loss        \n",
    "        loss = F.binary_cross_entropy(output, target)\n",
    "        # do a backward pass (calculate gradients using automatic differentiation and backpropagation)\n",
    "        loss.backward()\n",
    "        # udpate parameters of network using calculated gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print logs\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, took {:.2f}s'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), time.time()-t))\n",
    "            t = time.time()\n",
    "\n",
    "\n",
    "        # WORK IN PROGRESS: skip rest of loop\n",
    "        # print('train batch index:', batch_idx)\n",
    "        # break\n",
    "       \n",
    "def calculate_unseen_loss(model, device, unseen_loader):\n",
    "    \"\"\"\n",
    "    Calculate loss for unseen data (validation or testing)\n",
    "    :return: cumulative loss\n",
    "    \"\"\"\n",
    "    # set model to inference mode (deactivate dropout / batch normalization).\n",
    "    model.eval()\n",
    "    # init cumulative loss\n",
    "    unseen_loss = 0\n",
    "    # no gradient calculation    \n",
    "    with torch.no_grad():\n",
    "        # iterate over test data\n",
    "        for data, target in unseen_loader:\n",
    "            # move data to device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # forward pass (calculate output of network for input)\n",
    "            output = model(data.float())\n",
    "            \n",
    "            # WORK IN PROGRESS: skip rest of loop\n",
    "            # continue\n",
    "            \n",
    "            # claculate loss and add it to our cumulative loss\n",
    "            unseen_loss += F.binary_cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "\n",
    "    # output results of test run\n",
    "    unseen_loss /= len(unseen_loader.dataset)\n",
    "    print('Average loss: {:.4f}\\n'.format(\n",
    "        unseen_loss, len(unseen_loader.dataset)))\n",
    "\n",
    "    return unseen_loss\n",
    "  \n",
    "    \n",
    "    \n",
    "def predict(model, device, data, context):\n",
    "    \"\"\"\n",
    "    Predict beat\n",
    "    :return: prediction\n",
    "    \"\"\"\n",
    "    # set model to inference mode (deactivate dropout / batch normalization).\n",
    "    model.eval()\n",
    "    output = None\n",
    "    # move data to device\n",
    "    data = torch.from_numpy(data[None, None, :, :])\n",
    "    data = data.to(device)\n",
    "    # no gradient calculation\n",
    "    with torch.no_grad():\n",
    "        output = model(data.float())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    print('Training network...')\n",
    "\n",
    "    # parameters for NN training\n",
    "    args = Args()\n",
    "    args.batch_size = batch_size #1 #64\n",
    "    args.max_epochs = num_epochs #25 #1000\n",
    "    args.patience = patience #4\n",
    "    args.lr = lr # 0.001, 0.0001\n",
    "    args.momentum = 0.5 #UNUSED\n",
    "    args.log_interval = 100 #100\n",
    "    args.context = feature_context #5\n",
    "    args.hop_size = traininig_hop_size\n",
    "\n",
    "    # setup pytorch\n",
    "    torch.manual_seed(SEED)\n",
    "    \n",
    "    # create model and optimizer\n",
    "    model = BeatNet().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # setup our datasets for training, evaluation and testing\n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True} if USE_CUDA else {'num_workers': 4}\n",
    "    train_loader = torch.utils.data.DataLoader(BeatSet(train_f, train_t, args.context, args.hop_size),\n",
    "                                               batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    valid_loader = torch.utils.data.DataLoader(BeatSet(valid_f, valid_t, args.context, args.hop_size),\n",
    "                                               batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(BeatSet(test_f, test_t, args.context, args.hop_size),\n",
    "                                              batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    # main training loop\n",
    "    best_validation_loss = 9999\n",
    "    cur_patience = args.patience\n",
    "    for epoch in range(1, args.max_epochs + 1):\n",
    "        # run one epoch of NN training\n",
    "        train_one_epoch(args, model, DEVICE, train_loader, optimizer, epoch)\n",
    "        \n",
    "        # WORK IN PROGRESS: \n",
    "        # return\n",
    "        \n",
    "        # validate on validation set\n",
    "        print('\\nValidation Set:')\n",
    "        validation_loss = calculate_unseen_loss(model, DEVICE, valid_loader)\n",
    "        # check for early stopping\n",
    "        if validation_loss < best_validation_loss:\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_PATH, MODEL_NAME + '.model'))\n",
    "            best_validation_loss = validation_loss\n",
    "            cur_patience = args.patience\n",
    "        else:\n",
    "            # if performance does not improve, we do not stop immediately but wait for 4 iterations (patience)\n",
    "            if cur_patience <= 0:\n",
    "                print('Early stopping, no improvement for %d epochs...' % args.patience)\n",
    "                break\n",
    "            else:\n",
    "                print('No improvement, patience: %d' % cur_patience)\n",
    "                cur_patience -= 1\n",
    "\n",
    "    # testing on test data\n",
    "    print('Evaluate network...')\n",
    "    print('Test Set:')\n",
    "    # calculate loss for test set\n",
    "    calculate_unseen_loss(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(test_features): \n",
    "    args = Args()\n",
    "    args.context = feature_context #5\n",
    "    \n",
    "    torch.manual_seed(SEED)\n",
    "    \n",
    "    # load model\n",
    "    model = BeatNet().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(os.path.join(MODEL_PATH, MODEL_NAME + '.model')))\n",
    "    print('model loaded...')\n",
    "    \n",
    "    # calculate actual output for the test data\n",
    "    results_cnn = [None for _ in range(len(test_features))]\n",
    "    # iterate over test tracks\n",
    "    for test_idx, cur_test_feat in enumerate(test_features):\n",
    "        if test_idx % 100 == 0:\n",
    "            completion = int((test_idx / len(test_features))*100)\n",
    "            print(str(completion)+'% complete...')\n",
    "        \n",
    "        # run the inference method\n",
    "        result = predict(model, DEVICE, cur_test_feat, args.context)\n",
    "        results_cnn[test_idx] = result.cpu().numpy()\n",
    "\n",
    "    return results_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = None\n",
    "picked_beats = []\n",
    "\n",
    "if PREDICT:\n",
    "    # beat_picker = BeatTrackingProcessor(fps=FPS) # TODO: replace with OnsetPeakPickingProcessor(fps=FPS)\n",
    "    beat_picker = OnsetPeakPickingProcessor(fps=FPS, threshold=0.12, pre_avg=2.0, post_avg=2.0, pre_max=0.0, post_max=0.0) # TODO: replace with OnsetPeakPickingProcessor(fps=FPS)\n",
    "    \n",
    "    # predict beats\n",
    "    if VERBOSE:\n",
    "        print('predicting...')\n",
    "    predicted = run_prediction(test_f) #[test_t[0], test_t[1]]\n",
    "    \n",
    "    # pick peaks\n",
    "    if VERBOSE:\n",
    "        print('picking beats...')\n",
    "        set_current_display(len(predicted))\n",
    "        \n",
    "    for i, pred in enumerate(predicted):\n",
    "        picked = beat_picker(pred.squeeze(0)) # squeeze cause the dimensions are (1, frame_num, cause of the batch)!!!\n",
    "        picked_beats.append(picked)\n",
    "        \n",
    "        if VERBOSE:\n",
    "            display_progress(i)\n",
    "\n",
    "    if VERBOSE:\n",
    "        print('\\n')\n",
    "    \n",
    "    # evaluate results\n",
    "    if VERBOSE:\n",
    "        print('evaluating results...')\n",
    "        set_current_display(len(picked_beats))\n",
    "        \n",
    "    evals = []\n",
    "    for i, beat in enumerate(picked_beats):\n",
    "        e = madmom.evaluation.beats.BeatEvaluation(beat, test_anno[i])\n",
    "        evals.append(e)\n",
    "        \n",
    "        if VERBOSE:\n",
    "            display_progress(i)\n",
    "\n",
    "    if VERBOSE:\n",
    "        print('\\n')\n",
    "    \n",
    "    mean_eval = madmom.evaluation.beats.BeatMeanEvaluation(evals)\n",
    "    print(mean_eval)\n",
    "    \n",
    "    # print('F-Measure:', mean_eval.fmeasure)\n",
    "    # print('CMLc:', mean_eval.cmlc, 'CMLt:', mean_eval.cmlt, 'AMLc:', mean_eval.amlc, 'AMLt:', mean_eval.amlt)\n",
    "    # print('Information Gain:', mean_eval.information_gain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
