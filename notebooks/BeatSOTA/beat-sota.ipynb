{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beat SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import madmom\n",
    "from madmom.utils import search_files\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "# random seed\n",
    "SEED = 1\n",
    "\n",
    "# cuda configuration\n",
    "DISABLE_CUDA = False\n",
    "USE_CUDA = not DISABLE_CUDA and torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda:0\" if USE_CUDA else \"cpu\")\n",
    "print(\"CURRENT DEVICE:\", DEVICE)\n",
    "\n",
    "# paths\n",
    "CURRENT_PATH = os.getcwd()\n",
    "\n",
    "MODEL_NAME = 'beat_sota'\n",
    "MODEL_PATH = os.path.join(CURRENT_PATH, 'models')\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)  \n",
    "    \n",
    "FEATURE_EXT = '.feat.npy'\n",
    "FEATURE_PATH = os.path.join(CURRENT_PATH, 'features')\n",
    "ANNOTATION_EXT = '.beats'\n",
    "ANNOTATION_PATH = '../../../datasets/beat_boeck'\n",
    "\n",
    "# feature parameters\n",
    "# SR = 44100 # samping rate\n",
    "# FRAME_SIZE = 2048 # number of samples per frame\n",
    "FPS = 100 # frames / second\n",
    "# HOP_SIZE = int(SR / FPS) # hop size = 10ms or 441 samples\n",
    "# TODO: Mel bins should be from 30 to 17000 Hz !!!\n",
    "# NUM_BANDS = 81 # number of mel bins\n",
    "\n",
    "TRAIN_SPLIT_POINT = 0.7\n",
    "VALIDATION_SPLIT_POINT = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND LINE SUPPORT\n",
    "\n",
    "# TODO:\n",
    "\n",
    "VERBOSE = True # args.verbose\n",
    "\n",
    "if VERBOSE:\n",
    "    print('\\n---- EXECUTION STARTED ----\\n')\n",
    "    # print('Command line arguments:\\n\\n', args, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD FEATURES AND ANNOTATIONS, COMPUTE TARGETS\n",
    "\n",
    "# compute a target array for 1 feature (1 (0.5 on neighbouring frames) for beat, 0 for non-beat in each frame)\n",
    "# NOTE: if there is an annotation that is after the last frame, ignore it\n",
    "def compute_target(times, num_frames):\n",
    "    \"\"\"\n",
    "    if len(times) > 0 and np.max(times) * FPS > num_frames and VERBOSE:\n",
    "        print(\"Maximum time is larger than number of samples - cutting times.\")\n",
    "        print(np.max(times)*FPS, num_frames)\n",
    "    \"\"\"\n",
    "\n",
    "    target = np.zeros(num_frames)\n",
    "    for idx, time in enumerate(times):\n",
    "        time_idx = int(np.rint(time*FPS))\n",
    "        if time_idx < num_frames:\n",
    "            target[time_idx] = 1\n",
    "            \n",
    "            # for 0.5 probabilities on either side of beat frame\n",
    "            if(time_idx > 0):\n",
    "                target[time_idx-1] = 0.5\n",
    "            if(time_idx < (num_frames-1)):\n",
    "                target[time_idx+1] = 0.5\n",
    "\n",
    "    return target\n",
    "\n",
    "def init_targets(annos, feats):\n",
    "    targs = []\n",
    "    for anno, feat in zip(annos, feats):\n",
    "        targ = compute_target(anno, len(feat)) # time axis for length!\n",
    "        targs.append(targ)\n",
    "    return targs\n",
    "\n",
    "\n",
    "\n",
    "# load and initialize feature data\n",
    "feat_paths = search_files(FEATURE_PATH, FEATURE_EXT)\n",
    "anno_paths = search_files(ANNOTATION_PATH, ANNOTATION_EXT)\n",
    "\n",
    "features = [np.load(p) for p in feat_paths]\n",
    "# librosa has time in rows, madmom is transposed! now first index is time as in madmom!\n",
    "features = [np.transpose(f) for f in features]\n",
    "annotations = [madmom.io.load_beats(p) for p in anno_paths]\n",
    "targets = init_targets(annotations, features)\n",
    "\n",
    "assert len(features) == len(targets)\n",
    "\n",
    "first_idx = int(len(features)*TRAIN_SPLIT_POINT)\n",
    "second_idx = int(len(features)*VALIDATION_SPLIT_POINT)\n",
    "\n",
    "train_f = features[: first_idx]\n",
    "train_t = targets[: first_idx]\n",
    "valid_f = features[first_idx : second_idx]\n",
    "valid_t = targets[first_idx : second_idx]\n",
    "test_f = features[second_idx :]\n",
    "test_t = targets[second_idx :]\n",
    "\n",
    "if VERBOSE:\n",
    "    print(len(features), 'feature spectrogram files loaded, with example shape:', features[0].shape)\n",
    "    print(len(annotations), 'feature annotation files loaded, with example shape:', annotations[0].shape)\n",
    "    print(len(targets), 'targets computed, with example shape:', targets[0].shape)\n",
    "    print(len(train_f), 'training features', len(valid_f), 'validation features and', len(test_f), 'test features')\n",
    "  \n",
    "# Conacatenate spectrograms along the time axis\n",
    "# features = np.concatenate(features, axis=1)\n",
    "# print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK PARAMETERS\n",
    "\n",
    "# CNN\n",
    "\n",
    "# filters\n",
    "cnn_in_size = 1\n",
    "cnn_h_size = 16\n",
    "\n",
    "# kernels\n",
    "cnn_k_1_size = 3\n",
    "cnn_k_2_size = (1, 8)\n",
    "cnn_padding = (1,0)\n",
    "cnn_max_pool_k_size = (1,3)\n",
    "\n",
    "cnn_dropout_rate = 0.1\n",
    "\n",
    "# TCN\n",
    "\n",
    "# filters\n",
    "tcn_h_size = 16\n",
    "\n",
    "# kernels\n",
    "tcn_k_size = 5\n",
    "tcn_init_padding = 2\n",
    "tcn_init_dilation = 1\n",
    "\n",
    "tcn_dropout_rate = 0.1\n",
    "\n",
    "tcn_layer_num = 11\n",
    "\n",
    "# number of epochs\n",
    "num_epochs = 1 #10\n",
    "\n",
    "# learning rate\n",
    "lr = 0.001 # reduce by a factor of five whenever <condition from paper> is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEAT NETWORK CLASS and DATA SET CLASS for DATA LOADER\n",
    "\n",
    "class BeatNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BeatNet, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Conv2d(cnn_in_size, cnn_h_size, cnn_k_1_size, padding=cnn_padding),\n",
    "            nn.BatchNorm2d(cnn_h_size),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size = cnn_max_pool_k_size),\n",
    "            nn.Dropout2d(p = cnn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Conv2d(cnn_h_size, cnn_h_size, cnn_k_1_size, padding=cnn_padding),\n",
    "            nn.BatchNorm2d(cnn_h_size),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size = cnn_max_pool_k_size),\n",
    "            nn.Dropout2d(p = cnn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.l3 = nn.Sequential(\n",
    "            nn.Conv2d(cnn_h_size, cnn_h_size, cnn_k_2_size),\n",
    "            # nn.BatchNorm2d(cnn_h_size), # cant use because spec is reduced to 1x1\n",
    "            # NOTE: if needed try Instance normalization (InstanceNorm2d)\n",
    "            nn.ELU(),\n",
    "            nn.Dropout2d(p = cnn_dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.ld = self.init_dilated_layers()\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        out = self.l1(x)\n",
    "        # print(out.shape)\n",
    "\n",
    "        out = self.l2(out)\n",
    "        # print(out.shape)\n",
    "\n",
    "        out = self.l3(out)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        out.squeeze_(-1)\n",
    "        # print(out.shape)\n",
    "        \n",
    "        for i in range(tcn_layer_num):\n",
    "            out = self.ld[i](out)\n",
    "        \n",
    "        print(out.shape)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    # create a list containing dilated convolutional layers\n",
    "    def init_dilated_layers(self):\n",
    "        layers = []\n",
    "        dilation = tcn_init_dilation\n",
    "        padding = tcn_init_padding\n",
    "        \n",
    "        for i in range(tcn_layer_num):\n",
    "            next_layer = nn.Sequential(\n",
    "                nn.Conv1d(tcn_h_size, tcn_h_size, tcn_k_size, padding=padding, dilation=dilation),\n",
    "                nn.BatchNorm1d(tcn_h_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p = tcn_dropout_rate)\n",
    "            )\n",
    "            layers.append(next_layer)\n",
    "            \n",
    "            dilation = dilation*2\n",
    "            padding = tcn_init_padding * dilation\n",
    "        #print('TCN', self.ld)\n",
    "        \n",
    "        return layers\n",
    "\n",
    "\n",
    "\n",
    "# Dataset for DataLoader (items are pairs of 5x81 (time x freq.) spectrogram snippets and 0-1 (0.5) target values)\n",
    "class BeatSet(Dataset):\n",
    "    def __init__(self, feat_list, targ_list, context):\n",
    "        self.features = feat_list\n",
    "        self.targets = targ_list\n",
    "        self.context = context\n",
    "        self.side = int((context-1)/2)\n",
    "        # list with snippet count per track\n",
    "        self.snip_cnt = []\n",
    "        # overall snippet count\n",
    "        total_snip_cnt = 0\n",
    "        # calculate overall number of snippets we can get from our data\n",
    "        for feat in feat_list:\n",
    "            cur_len = int(np.ceil(feat.shape[0] - self.side*2))\n",
    "            \n",
    "            # GUARD TO AVOID NEGATIVE SNIPPER COUNT!\n",
    "            cur_len = cur_len if cur_len > 0 else 1\n",
    "            \n",
    "            self.snip_cnt.append(cur_len)\n",
    "            total_snip_cnt += cur_len\n",
    "        self.length = int(total_snip_cnt)\n",
    "        super(BeatSet, self).__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # find track which contains snippet with index [index]\n",
    "        overal_pos = 0\n",
    "        for idx, cnt in enumerate(self.snip_cnt):\n",
    "            # check if this track contains the snippet with index [index]\n",
    "            if index < overal_pos+cnt:\n",
    "                break\n",
    "            else:\n",
    "                # if not, add the current tracks snippet count to the overall snippet count already visited\n",
    "                overal_pos += cnt\n",
    "\n",
    "        # calculate the position of the snippet within the track nr. [idx]\n",
    "        position = index-overal_pos\n",
    "        position += self.side\n",
    "\n",
    "        # get snippet and target\n",
    "        \n",
    "        # GUARD TO AVOID NEGATIVE STARTING INDEX!\n",
    "        left = position-self.side if position-self.side < 0 else 0\n",
    "        \n",
    "        sample = self.features[idx][(position-self.side):(position+self.side+1)]\n",
    "        target = self.targets[idx][position]\n",
    "        # convert to PyTorch tensor and return (unsqueeze is for extra dimension, asarray is cause target is scalar)\n",
    "        return torch.from_numpy(sample).unsqueeze_(0), torch.from_numpy(np.asarray(target))\n",
    "\n",
    "\n",
    "\n",
    "# helper class for arguments\n",
    "class Args:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN / TEST / PREDICT\n",
    "\n",
    "def train_one_epoch(args, model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Training for one epoch.\n",
    "    \"\"\"\n",
    "    # set model to training mode (activate dropout / batch normalization).\n",
    "    model.train()\n",
    "    t = time.time()\n",
    "    # iterate through all data using the loader\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # move data to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # reset optimizer (clear previous gradients)\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass (calculate output of network for input)\n",
    "        output = model(data.float())\n",
    "        \n",
    "        # WORK IS PROGRESS: skip rest of loop\n",
    "        print('train batch index:', batch_idx)\n",
    "        break\n",
    "        \n",
    "        # calculate loss        \n",
    "        loss = F.binary_cross_entropy(output, target)\n",
    "        # do a backward pass (calculate gradients using automatic differentiation and backpropagation)\n",
    "        loss.backward()\n",
    "        # udpate parameters of network using calculated gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print logs\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, took {:.2f}s'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), time.time()-t))\n",
    "            t = time.time()\n",
    "\n",
    "\n",
    "       \n",
    "def calculate_unseen_loss(model, device, unseen_loader):\n",
    "    \"\"\"\n",
    "    Calculate loss for unseen data (validation or testing)\n",
    "    :return: cumulative loss\n",
    "    \"\"\"\n",
    "    # set model to inference mode (deactivate dropout / batch normalization).\n",
    "    model.eval()\n",
    "    # init cumulative loss\n",
    "    unseen_loss = 0\n",
    "    # no gradient calculation    \n",
    "    with torch.no_grad():\n",
    "        # iterate over test data\n",
    "        for data, target in unseen_loader:\n",
    "            # move data to device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # forward pass (calculate output of network for input)\n",
    "            output = model(data.float())\n",
    "            \n",
    "            # WORK IS PROGRESS: skip rest of loop\n",
    "            continue\n",
    "            \n",
    "            # claculate loss and add it to our cumulative loss\n",
    "            unseen_loss += F.binary_cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "\n",
    "    # output results of test run\n",
    "    unseen_loss /= len(unseen_loader.dataset)\n",
    "    print('Average loss: {:.4f}\\n'.format(\n",
    "        unseen_loss, len(unseen_loader.dataset)))\n",
    "\n",
    "    return unseen_loss\n",
    "  \n",
    "    \n",
    "    \n",
    "def predict(model, device, data):\n",
    "    \"\"\"\n",
    "    Predict beat\n",
    "    :return: prediction\n",
    "    \"\"\"\n",
    "    # set model to inference mode (deactivate dropout / batch normalization).\n",
    "    model.eval()\n",
    "    output = None\n",
    "    # move data to device\n",
    "    data = torch.from_numpy(data)\n",
    "    data = data.to(device)\n",
    "    # no gradient calculation\n",
    "    with torch.no_grad():\n",
    "        output = model(data.float())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    print('Training network...')\n",
    "\n",
    "    # parameters for NN training\n",
    "    args = Args()\n",
    "    args.batch_size = 1 #64\n",
    "    args.max_epochs = 1 #25 #1000\n",
    "    args.patience = 4\n",
    "    args.lr = 0.01 # 0.001, 0.0001\n",
    "    args.momentum = 0.5 #UNUSED\n",
    "    args.log_interval = 100 #100\n",
    "    args.context = 8193 #5\n",
    "\n",
    "    # setup pytorch\n",
    "    torch.manual_seed(SEED)\n",
    "    \n",
    "    # create model and optimizer\n",
    "    model = BeatNet().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # setup our datasets for training, evaluation and testing\n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True} if USE_CUDA else {'num_workers': 4}\n",
    "    train_loader = torch.utils.data.DataLoader(BeatSet(train_f, train_t, args.context),\n",
    "                                               batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    valid_loader = torch.utils.data.DataLoader(BeatSet(valid_f, valid_t, args.context),\n",
    "                                               batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(BeatSet(test_f, test_t, args.context),\n",
    "                                              batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    # main training loop\n",
    "    best_validation_loss = 9999\n",
    "    cur_patience = args.patience\n",
    "    for epoch in range(1, args.max_epochs + 1):\n",
    "        # run one epoch of NN training\n",
    "        train_one_epoch(args, model, DEVICE, train_loader, optimizer, epoch)\n",
    "        \n",
    "        # WORK IN PROGRESS: \n",
    "        return\n",
    "        \n",
    "        # validate on validation set\n",
    "        print('\\nValidation Set:')\n",
    "        validation_loss = calculate_unseen_loss(model, DEVICE, valid_loader)\n",
    "        # check for early stopping\n",
    "        if validation_loss < best_validation_loss:\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_PATH, MODEL_NAME + '.model'))\n",
    "            best_validation_loss = validation_loss\n",
    "            cur_patience = args.patience\n",
    "        else:\n",
    "            # if performance does not improve, we do not stop immediately but wait for 4 iterations (patience)\n",
    "            if cur_patience <= 0:\n",
    "                print('Early stopping, no improvement for %d epochs...' % args.patience)\n",
    "                break\n",
    "            else:\n",
    "                print('No improvement, patience: %d' % cur_patience)\n",
    "                cur_patience -= 1\n",
    "\n",
    "    # testing on test data\n",
    "    print('Evaluate network...')\n",
    "    print('Test Set:')\n",
    "    # calculate loss for test set\n",
    "    calculate_unseen_loss(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT YET USABLE!!!\n",
    "def run_prediction(test_features): \n",
    "    torch.manual_seed(SEED)\n",
    "    \n",
    "    # load model\n",
    "    model = BeatNet().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(os.path.join(MODEL_PATH, MODEL_NAME + '.model')))\n",
    "    print('model loaded...')\n",
    "    \n",
    "    # calculate actual output for the test data\n",
    "    results_cnn = [None for _ in range(len(test_features))]\n",
    "    # iterate over test tracks\n",
    "    for test_idx, cur_test_feat in enumerate(test_features):\n",
    "        if test_idx % 100 == 0:\n",
    "            completion = int((test_idx / len(test_features))*100)\n",
    "            print(str(completion)+'% complete...')\n",
    "        \n",
    "        # run the inference method\n",
    "        result = predict(model, DEVICE, cur_test_feat)\n",
    "        results_cnn[test_idx] = result.numpy()[0]\n",
    "\n",
    "    return results_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted = run_prediction(test_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
