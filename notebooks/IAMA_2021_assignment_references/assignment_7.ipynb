{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af22af3c51ef2859",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Intelligent Audio and Music Analysis Assignment 7\n",
    "\n",
    "This assignment accounts for the last 50 points of the 3rd and last assignment block (100 points total)\n",
    "\n",
    "Assignment is mainly **free form**, the goal is to apply what has been practiced so far. For implementing assignment 7, best practice is to follow the code structures from previous assignments and reuse as much code as possible (this makes it easier for us to review it). You can use any libraries, however, we recommend you use: madmom, librosa, pyTorch, etc. (the libraries we have used so far).\n",
    "\n",
    "\n",
    "### GPU Support\n",
    "Our JupyterHub, unfortunately, does not yet provide GPU support. Nevertheless, this assignemnt can be run as-is on JupyterHub, however training of the neural network will take a long time.\n",
    "\n",
    "In order to speed up training if you are in a hurry, you can run this notebook on any local machine with GPU and cuda support, or alternatively use infrastructure like [Google colab](https://colab.research.google.com/) and drive, if you have a google account.\n",
    "\n",
    "Simply upload your solved notebook and necessary other files, like output model file, back to JupyterHub for your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7ed23be263a52e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "NOT running in colab...\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# This code block enables this notebook to run on google colab.\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    print('Running in colab...\\n===================')\n",
    "    COLAB = True\n",
    "    !pip install madmom torch==1.4.0 torchvision==0.5.0 librosa --upgrade\n",
    "    print('Installed dependencies!\\n=======================')\n",
    "\n",
    "    if not os.path.exists('data'):\n",
    "        print('Downloading data...\\n===================')\n",
    "        !mkdir data\n",
    "        !cd data\n",
    "        !wget https://zenodo.org/record/45739/files/TUT-acoustic-scenes-2016-development.audio.1.zip?download=1\n",
    "        !wget https://zenodo.org/record/45739/files/TUT-acoustic-scenes-2016-development.audio.2.zip?download=1\n",
    "        !wget https://zenodo.org/record/45739/files/TUT-acoustic-scenes-2016-development.audio.3.zip?download=1\n",
    "        !wget https://zenodo.org/record/45739/files/TUT-acoustic-scenes-2016-development.audio.4.zip?download=1\n",
    "        !wget https://zenodo.org/record/45739/files/TUT-acoustic-scenes-2016-development.audio.5.zip?download=1\n",
    "        !wget https://zenodo.org/record/45739/files/TUT-acoustic-scenes-2016-development.audio.6.zip?download=1\n",
    "        !wget https://zenodo.org/record/45739/files/TUT-acoustic-scenes-2016-development.audio.7.zip?download=1\n",
    "        !wget https://zenodo.org/record/45739/files/TUT-acoustic-scenes-2016-development.audio.8.zip?download=1\n",
    "        !wget https://zenodo.org/record/45739/files/TUT-acoustic-scenes-2016-development.doc.zip?download=1\n",
    "        !wget https://zenodo.org/record/45739/files/TUT-acoustic-scenes-2016-development.error.zip?download=1\n",
    "        !wget https://zenodo.org/record/45739/files/TUT-acoustic-scenes-2016-development.meta.zip?download=1\n",
    "            \n",
    "        !wget https://zenodo.org/record/165995/files/TUT-acoustic-scenes-2016-evaluation.audio.1.zip?download=1\n",
    "        !wget https://zenodo.org/record/165995/files/TUT-acoustic-scenes-2016-evaluation.audio.2.zip?download=1\n",
    "        !wget https://zenodo.org/record/165995/files/TUT-acoustic-scenes-2016-evaluation.audio.3.zip?download=1\n",
    "        !wget https://zenodo.org/record/165995/files/TUT-acoustic-scenes-2016-evaluation.doc.zip?download=1\n",
    "        !wget https://zenodo.org/record/165995/files/TUT-acoustic-scenes-2016-evaluation.meta.zip?download=1\n",
    "            \n",
    "        !for file in *.*; do mv $file ${file%?download=1}; done\n",
    "        \n",
    "        !unzip \"*.zip\"\n",
    "        !rm *.zip\n",
    "        !cd ..\n",
    "\n",
    "    print('===================\\nMake sure you activated GPU support: Edit->Notebook settings->Hardware acceleration->GPU\\n==================')\n",
    "except:\n",
    "    print('=======================\\nNOT running in colab...\\n=======================')\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fe37cd78135067a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Audio Scene Classification\n",
    "\n",
    "Your task is to implement a solution to an auditory scene detection challenge, precisely the DCASE 2016 Acoustic Scene Classification task. Details about the challenge are provided on the [task website](http://dcase.community/challenge2016/task-acoustic-scene-classification).\n",
    "1. You are **free in choosing the strategy that you apply** and can also reuse and modify your implementation of previous assignments, e.g., by modifying the architecture to handle clips of 30 seconds length.\n",
    "2. **Follow the given evaluation strategies of the task**, in particular wrt. development and evaluation datasets and cross validation settings.\n",
    "3. Consider **reducing the amount of data** in a reasonable way, if necessary.\n",
    "4. **Compare your results** to the numbers reported on the task website and comment on you main findings.\n",
    "\n",
    "Remark: The goal is not to outperform the state of the art, but to experiment with a classification task in the general audio domain. Therefore, you can apply your existing solutions from the music domain and reflect upon the capabilities and limitations of your approach.\n",
    "\n",
    "The overall goal of this assignment is to implement the method in an elegant way and present your implementation in this notebook:\n",
    "1. **Illustrate your chosen architecture** e.g. by printing the individual layers and the shapes of the forward function if you choose a neural network approach (as we have done in previous assignments).\n",
    "2. **Use plots** to showcase features and evaluation results.\n",
    "3. Output your **final performance** and set it into context.\n",
    "\n",
    "The rough distribution of points is as follows:\n",
    "* 10 Points data preprocessing and data handling\n",
    "* 10 Points machine learning architecture (e.g. neural network and data loader)\n",
    "* 10 Points training method and evaluation\n",
    "* 10 Points results and conclusion\n",
    "* 10 Points overall presentation throughout the notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5b4af1581b02da49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 1: Data Processing (10 Points)\n",
    "\n",
    "If you work on JupyterHub, find the audiofiles in the shared folder as indicated in the cell below.\n",
    "Think about **reasonable features** to use and extract them for the audio files.\n",
    "The DCASE dataset is already split into **a development and an evaluation** set. The idea is to only use the evaluation set **once** at the very end when you are confident about your trained system.\n",
    "Only use the development set to draw your train/valid/test splits from.\n",
    "The dataset comes with **predefined splits** for four-fold cross-validation. Feel free to use your own training setup, but read and **follow the guidelines** that come in the documentation of the dataset!\n",
    "\n",
    "**Note**: Check the readme files in the dataset folder for more details!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of development audio files: 1170\n",
      "Total number of evaluation audio files: 390\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# get dataset path\n",
    "dataset_path = os.path.join(os.environ['HOME'], 'shared', 'data', 'assignment_7')\n",
    "if os.path.exists('data'):\n",
    "    dataset_path = 'data'\n",
    "\n",
    "development_path = os.path.join(dataset_path, 'TUT-acoustic-scenes-2016-development')\n",
    "evaluation_path = os.path.join(dataset_path, 'TUT-acoustic-scenes-2016-evaluation')\n",
    "\n",
    "development_audio_path = os.path.join(development_path, 'audio')\n",
    "development_annotation_file = os.path.join(development_path, 'meta.txt')\n",
    "development_error_file = os.path.join(development_path, 'error.txt')\n",
    "split_definition_path = os.path.join(development_path, 'evaluation_setup')\n",
    "\n",
    "evaluation_annotation_file = os.path.join(evaluation_path, 'meta.txt')\n",
    "evaluation_audio_path = os.path.join(evaluation_path, 'audio')\n",
    "\n",
    "# collect list of audio files:\n",
    "development_audio_files = [af for af in os.listdir(development_audio_path) if af.endswith('.wav')]\n",
    "evaluation_audio_files = [af for af in os.listdir(evaluation_audio_path) if af.endswith('.wav')]\n",
    "\n",
    "dev_audio_total_count = len(development_audio_files)\n",
    "eval_audio_total_count = len(evaluation_audio_files)\n",
    "\n",
    "print(f'Total number of development audio files: {dev_audio_total_count}')\n",
    "print(f'Total number of evaluation audio files: {eval_audio_total_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc521b5d76d8b1e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d27d427e4f69f428",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Put your data handling code here. \n",
    "# You can add additional cells below this one for structuring the notebook.\n",
    "# Feel free to add markdown cells / plots / tests / etc. if it helps your presentation.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "print('this is the reference implementation')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8897b8345f16e1a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Discussion\n",
    "\n",
    "Write down what choices you made regarding data structuring and feature extraction, feel free to refer to code/plots/etc. in cells above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-731075a98f8a1df9",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d92c736eab25f84c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 2: Machine Learning Approach (10 Points)\n",
    "\n",
    "Implement your audio scene classification method here. You are free to use any approach you find appropriate. As a hint: the easiest way to succeed is to adapt the neural network approach from assignment 6 (or 5), since convolutional neural networks have been shown to work very well for this task, and you can start with a running code base.\n",
    "\n",
    "### 2.1 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7dcea57a4c435adb",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement your machine learning architecture in the cells below. \n",
    "# You can add additional cells below this one for structuring the notebook.\n",
    "# Feel free to add markdown cells / plots / tests / etc. if it helps your presentation.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "print('this is the reference implementation')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab9e2c0276de260d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 Discussion\n",
    "Write down your choices and findings. Feel free to refer to code/plots/etc. in cells above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-26d1e2ced94de1e0",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-84d189277e6b8b1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3: Training, Inference, and Evaluation (10 Points)\n",
    "\n",
    "Depending on your choices for the machine learning model, implement the appropriate code to train and test it.\n",
    "For developing and training the model only use the development set. \n",
    "\n",
    "### 3.1 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-468de04cf5d3f6a3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Put your trainin and evaluation code in the cells below.\n",
    "# You can add additional cells below this one for structuring the notebook.\n",
    "# Feel free to add markdown cells / plots / tests / etc. if it helps your presentation.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "print('this is the reference implementation')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ccd683a5d9bdab60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.2 Discussion\n",
    "Write down your choices and findings. Feel free to refer to code/plots/etc. in cells above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5e714093652f39f1",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88bd2a921720331f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 4: Results and Conclusion (10 Points)\n",
    "\n",
    "Use the code cells below to calculate the final performance of the developed approach on the evaluation part of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b761a1d4ff608dd8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Put the evaluation code on the evaulation dataset in these code cells.\n",
    "# You can add additional cells below this one for structuring the notebook.\n",
    "# Feel free to add markdown cells / plots / tests / etc. if it helps your presentation.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "print('this is the reference implementation')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57187004bb828831",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 4.2 Discussion\n",
    "\n",
    "Compare your performance to the ones shown on the DCASE website, and discuss possible reasons for performance differences.\n",
    "Discuss your approach in the context of the other methods presented on the DCASE website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0008272fc2e0c668",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b6b5773d5570419c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Task 5: Overall Presentation (10 Points)\n",
    "\n",
    "Make sure your notebook **clearly presents your chosen approach** to the problem solution. If necessary, revisit the individual tasks and **add plots, outputs, code comments**, etc. to clearly explain what is going on.\n",
    "\n",
    "You do not need to overdo it (no endless prints or plots that bloat the notebook) - less is sometimes more - as a goal think about your peers in the lecture and make it so that they could easily understand what is going on in the notebook. Exemplary plots with overall metrics are usually a nice compromise."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
