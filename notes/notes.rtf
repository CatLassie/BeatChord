{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww22840\viewh13880\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 ZOOM LINK:\

\f1\b0 https://tuwien.zoom.us/j/96849549054?pwd=Tll1VmlMWjYvZy9Mem5pM1BZaDRGUT09#success
\f0\b \

\f1\b0 \
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\b \cf0 How to proceed:\

\f1\b0 TCN has to return same dimensions as it got (whatever 200 on time axis, 1 (squeezed) freq. and 16 channels), that has to somehow (dense layer ? 1x200 conv layer to simulate dense ?) be fed\
into a peak picker from madmom (for starters). madmom peak picker is easier and simpler than the Hidden Markov Model postprocessing. so its ok for now.\
\
Top Secret tip from Sebastian: chord recognition should be done with a simple network (2 conv layer and maybe 2 fully connected layer should be enough), it gives good results.\
BUT data preprocessing needs to be good, be smart about what exactly you feed into the network (frame sizes and etc ?)
\f0\b \
\
Concepts to read about:
\f1\b0 \
\
CNN - Convolutional Neural Network\
	GAP - Global Average Pooling (layer at end of CNN instead of dense layer ?)\
	TCN - Temporal Convolutional Network (dilation stuff)\
RNN - Recurrent Neural Network\
\
GMM - Gaussian Mixture Model\
CRF - Conditional Random Field (context sensitive classifier) (with Viterbi)\
HMM - Hidden Markov Model (is a special case of DBN)\
DBN - Dynamic Bayesian Network (approximated by a HMM)\
\
\
\

\f0\b How stuff is done:\
\

\f1\b0 General: mostly logMagnitutde logFrequency Spectrograms are used
\f0\b \

\f1\b0 \
\
1: beat and tempo\
\
Beat Tracking:\
\
Test: 8-fold cross validation\
\
\
\
2: chord and key\
\
8192 frame size with 24 bins / octave (quarter tone)\
\
Chord Recognition:\
LogAmp Spectrogram\
CNN (for feature extraction and chord labelling per frame) (with GAP)\
CRF for chord sequence decoding\
\
Test: 8-fold cross validation\
\
2a: key classification\
\
\
\
3: drum transcription (joint with beats)\
\

\f0\b \
\
Questions:\

\f1\b0 How HMMs are used for decoding beats -> paper!\
No septaccords and incomplete chords -> no!\
What are stacks in TCN -> increase processing power w/o increasing receptive field \
Temporal resolution for beats is better than for chords usually (pooling (maybe not global) along time axis for chords ? Like in beats paper 2 for tempo) -> maybe, don\'92t think about it yet\
Beat improved by chord and the other way around (not asymmetric like beat improved by tempo) -> yes!\
Experiment like paper 2: unseen set, chord set -> evaluate beat, then evaluate chord just for fun and\
				     unseen set, beat set -> evaluate chord, then evaluate beat just for fun (too see if its not worse ?)\
				-> yes! like paper 2 and in both directions\
}