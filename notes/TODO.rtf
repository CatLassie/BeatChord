{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww17140\viewh13880\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 + fix CUDA on server\
- add command line input support to scripts\
- get papers for beat architecture\
- read Richards article about dilated nets\
\
+ write an abstract (proposal) soon\
- add code to tu reposiroty\
\
+ add zero padding to avoid error (just to fit context) AND zero padding to start from frame 1 (add context halves on both sides)\
\
- fix big mean loss\
- add logic to init number of layers just based on context param.\
- dynamic learning rate\
\
\
Experiments:\
context (1000 vs 2000), -> 1000 wins by 10%\
0-pad (0 pad vs first frame) -> 0-pad wins by a small margin (dsiable 1frame for testing)\
batch size ! (1 vs 8)\
layer number (16 vs 32 ?)\
stacked TCN layers\
\
\
28-03-2021\
- rwc for beats\
- rwc for chords\
- feat / annotation paths from txt file\
- beat + chord targets\
- data folder common for beat and chord (all data should be per dataset and not per feature/datase, model/dataset, etc)\
+ TRAIN BEAT ON GTZAN TOO (NOOO! FEATURES ARE DIFFERENT! MEL BINS AND STUFF!)\
- 0-padding  for chord prediction (N chord) to not lose 1.5second worth of score at start and end\
\
\
\
MTL ideas:\
- chords as extra inputs for beat net\
- beat net architecture for chords alone\
- beat net architecture for both beats and chords (softmax for beats too ? as neuron 14 and 15 ?, naaah, more like 2 final layers?)\
- split architecture after conv layers ?\
- split architecture even earlier ? (after some conv layers)\
- if all else fails, read about skip connections (additive stuff)\
\
- ALSO TRY CHORD + SCALE MTL TASK! (root + maj/min)\
\
- print separate losses and sum\
- print current model and datasets in use\
+ Further training of existing model\
- 8 fold cross validation\
- write a google doc for Richard about which MTL papers Ive seen and ask what to read\
- check data preprocessor script from Richard\
\
- beat architecture for chords\
- 1 head for 2 tasks, just use all neurons in 1 layer\
- use 1 input or concatenate beat and chord inputs (along freq?)\
- sigmoid vs softmax on output ? (maybe try to take the output from last layer and use different activation function + loss on them ?)\
\
\
QUESTIONS:\
- whats with the new datasets (they have audio but not features, how do I get the 91 frequency features)\
- disabled loss function for task that is not being trained on ? (if only training on chord -> scale loss disabled)\
- freeze layers for task that is not trained?\
- procedure: train first dataset for both tasks -> evaluate on third test dataset\
		   train first dataset for both tasks and second dataset on first task -> evaluate on third test dataset (see if second task improved)\
		  (optional intermediate) train first dataset for both tasks and second dataset on first task -> evaluate on second datasets second task\
\
\
\
}