{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww17140\viewh13880\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 + fix CUDA on server\
- add command line input support to scripts\
- get papers for beat architecture\
- read Richards article about dilated nets\
\
+ write an abstract (proposal) soon\
- add code to tu reposiroty\
\
+ add zero padding to avoid error (just to fit context) AND zero padding to start from frame 1 (add context halves on both sides)\
\
- fix big mean loss\
- add logic to init number of layers just based on context param.\
- dynamic learning rate\
\
\
Experiments:\
context (1000 vs 2000), -> 1000 wins by 10%\
0-pad (0 pad vs first frame) -> 0-pad wins by a small margin (dsiable 1frame for testing)\
batch size ! (1 vs 8)\
layer number (16 vs 32 ?)\
stacked TCN layers\
\
\
28-03-2021\
- rwc for beats\
- rwc for chords\
- feat / annotation paths from txt file\
- beat + chord targets\
- data folder common for beat and chord (all data should be per dataset and not per feature/datase, model/dataset, etc)\
+ TRAIN BEAT ON GTZAN TOO (NOOO! FEATURES ARE DIFFERENT! MEL BINS AND STUFF!)\
- 0-padding  for chord prediction (N chord) to not lose 1.5second worth of score at start and end\
\
\
\
MTL ideas:\
- chords as extra inputs for beat net\
- beat net architecture for chords alone\
- beat net architecture for both beats and chords (softmax for beats too ? as neuron 14 and 15 ?, naaah, more like 2 final layers?)\
- split architecture after conv layers ?\
- split architecture even earlier ? (after some conv layers)\
- if all else fails, read about skip connections (additive stuff)\
\
- ALSO TRY CHORD + SCALE MTL TASK! (root + maj/min)\
\
- print separate losses and sum\
- print current model and datasets in use\
+ Further training of existing model\
- 8 fold cross validation\
- write a google doc for Richard about which MTL papers Ive seen and ask what to read\
- check data preprocessor script from Richard\
\
+ beat architecture for chords\
- 1 head for 2 tasks, just use all neurons in 1 layer\
- use 1 input or concatenate beat and chord inputs (along freq?)\
- sigmoid vs softmax on output ? (maybe try to take the output from last layer and use different activation function + loss on them ?)\
	- or try softmax for beats\
- deal with datasets that have only 1 type of annotations \
	- like mtl chord + take care of the dataloader and target creation (fill em with 0 ?) + let user select what to predict (beat/chord/both)\
- maybe use 14 neuron last layer -> use sigmoid on neuron 14 and softmax on first 13 and add up losses\
	- or 15 neurons and 2 softmax activation functions (13 + 2)\
HINT: dont do further training! train new model with extra data because further training probably overwrites any previous training,\
	also "make sure to have batches that have all kinds of targets, cause if not your network will jump back and forth between learning 2 tasks"\
	shuffling data again should do the trick (after returning it from feat script)\
	also maybe have the dataloader ship a flag that says whether chord or beat data is present (to know which loss to disable)\
	HOW TO HAVE 1 BATCH WITH DIFFERENT TARGETS?!\
\
QUESTIONS:\
- whats with the new datasets (they have audio but not features, how do I get the 91 frequency features)\
- disabled loss function for task that is not being trained on ? (if only training on chord -> scale loss disabled)\
- freeze layers for task that is not trained?\
- procedure: train first dataset for both tasks -> evaluate on third test dataset\
		   train first dataset for both tasks and second dataset on first task -> evaluate on third test dataset (see if second task improved)\
		  (optional intermediate) train first dataset for both tasks and second dataset on first task -> evaluate on second datasets second task\
\
\
\
}