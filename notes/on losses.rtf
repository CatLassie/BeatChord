{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww17120\viewh13880\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 - binary cross entropy takes input [0:1] and labels class with 1 if value is above 0,5s\
- BCE can be used with sigmoid for exmaple, but not with ReLu ( >= 0, and not [0,1])\
- BCE can't use softmax cause cause softmax outputs sum up to 1, makes 0.5 unlikely when there are many neurons\
- BCE is for 2 class classification (d'uh) -> 1-hot encoding needed\
- BCEWIthLogitsLoss -> is like BCE but it applies sigmoid internally\
- CE is for multiclass classification and needs raw values (and uses softmax on them internally)\
- NLLLoss is as CE, but doesnt use softax internally so needs to be applied before\
\
- BCEWIthLogitsLoss == BCE + Sigmoid\
- CrossEntropyLoss == NLLLoss + Softmax (nn.LogSoftmax )\
Note: NLLLoss means Negative Log Likelyhood Loss where NLL is -log_2(P(x)), where P(x) is the probability of an event x (same as P(X=e), where e is event that random variable X can have)\
Note: random variable is a set of events X = \{e1, e2, e3...\}, P(X=e1) is the probability of e1\
\
FIRST IDEA:\
- use sigmoid for all 13 chords and 1 beat\
- use one BCE loss function\
- 1-hot encode chords\
- use 1 extra neuron for beat and 1 extra neuron for chord to encode that there are no targets (mabe set it to -1 on tragets)\
	- or maybe set -1 on all 13 / 1 neurons when there is no target for respective task ? is it allowed ?\
\
\
SECOND IDEA:\
- dont use sigmoid for beat, just feed it into CE as is\
	- probably wont work with 0,5 targets, targets need to be classes numbered (0 - no beat, 1 - beat)\
\
FIND OUT:\
- can I use BCE with a vector of values ? (13+1 sigmoid)\
- }